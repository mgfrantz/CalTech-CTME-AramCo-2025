{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgfrantz/CalTech-CTME-AramCo-2025/blob/main/notebooks/02_fine_tune_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA9sUDBfwiM9"
      },
      "source": [
        "# Part 1: Dataset Preparation\n",
        "\n",
        "Previously, we created a dataset of question/sql query pairs and validated them against actual SQLite databases.\n",
        "Now that we have this data, our goal is to fine-tune a model to accept a sql schema and a quesiton and output a sqlite query.\n",
        "\n",
        "The first step in this process is preparing our dataset.\n",
        "While there are many [dataset formats](https://docs.axolotl.ai/docs/dataset-formats/), it's important to use the **same dataset format your base model was trained on.**\n",
        "So for example if you have a chat model, you should make sure your dataset is formatted for chat.\n",
        "This ensures you're not learning a new dataset format along with your task.\n",
        "A good way to do that is to look at the axolotl [examples](https://github.com/axolotl-ai-cloud/axolotl/tree/main/examples) - there are samples for most any model family you'd want to fine tune with sensible defaults.\n",
        "\n",
        "In our case, we will output a `.jsonl` file where each line contains the folowing information:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"conversations\": [\n",
        "        {\n",
        "            \"role\": <system, user, assistant>,\n",
        "            \"content\": \"some content\"\n",
        "        },\n",
        "        ...\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "We will follow this general format:\n",
        "\n",
        "- Message 1: our system prompt with general instructions\n",
        "- Message 2: our user message with database schema and user query\n",
        "- Message 3: our validated sql output (what we want to tune the model to output)\n",
        "\n",
        "This format is useful for almost any chat model, even proprietary for use in proprietarty fine-tuning ([openai docs](https://platform.openai.com/docs/guides/supervised-fine-tuning?formatting=jsonl)).\n",
        "This means you can prepare your data once, and fine-tune and compare many different models.\n",
        "\n",
        "Let's start by loading and observing our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toX4WhNCvIW4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK_4qRtOvIW6"
      },
      "outputs": [],
      "source": [
        "# If running this on colab, make sure to upload the parquet file and update the path.\n",
        "df = pd.read_parquet(\"../output/validated_dataset.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YifRBpdivIW6"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq6CVs-230ot"
      },
      "source": [
        "Now, let's create some utilities to get the schema of the database as a string so we can pass it to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6OvetrTvIW7"
      },
      "outputs": [],
      "source": [
        "# Utilities\n",
        "duckdb.execute(\"\"\"\n",
        "INSTALL sqlite;\n",
        "LOAD sqlite;\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "def query_sqlite(query: str, db_path: str) -> pd.DataFrame:\n",
        "    conn = duckdb.connect(db_path)\n",
        "    return conn.execute(query).fetch_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzeCD_vjvIW7"
      },
      "outputs": [],
      "source": [
        "path = df.db_path.iloc[0]\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlahhsYdvIW7"
      },
      "outputs": [],
      "source": [
        "tables = query_sqlite(\"SHOW TABLES\", path)\n",
        "tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdqZlSqwvIW7"
      },
      "outputs": [],
      "source": [
        "for table in tables.name:\n",
        "    print(table)\n",
        "    display(\n",
        "        t := query_sqlite(f\"DESCRIBE TABLE {table}\", path).dropna(how=\"all\", axis=1)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT4zfNoZvIW8"
      },
      "outputs": [],
      "source": [
        "def table_metadata(db_path: str) -> dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Get metadata for all tables in the database.\n",
        "    \"\"\"\n",
        "    tables = query_sqlite(\"SHOW TABLES\", db_path)\n",
        "    metadata = {}\n",
        "    for table in tables.name:\n",
        "        metadata[table] = query_sqlite(f\"DESCRIBE TABLE {table}\", db_path).dropna(\n",
        "            how=\"all\", axis=1\n",
        "        )\n",
        "    return metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weAvzz0DvIW8"
      },
      "outputs": [],
      "source": [
        "def format_schema_for_chat(metadata: dict[str, pd.DataFrame]) -> str:\n",
        "    \"\"\"\n",
        "    Format table metadata into a readable string for chat training.\n",
        "    \"\"\"\n",
        "    schema_lines = []\n",
        "\n",
        "    for table_name, df in metadata.items():\n",
        "        schema_lines.append(f\"Table: {table_name}\")\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            col_info = f\"  - {row['column_name']} ({row['column_type']}\"\n",
        "            if row[\"key\"] == \"PRI\":\n",
        "                col_info += \", PRIMARY KEY\"\n",
        "            elif pd.notna(row[\"key\"]) and row[\"key\"] != \"None\":\n",
        "                col_info += f\", {row['key']}\"\n",
        "            if row[\"null\"] == \"NO\":\n",
        "                col_info += \", NOT NULL\"\n",
        "            col_info += \")\"\n",
        "            schema_lines.append(col_info)\n",
        "\n",
        "        schema_lines.append(\"\")  # Add blank line between tables\n",
        "\n",
        "    return \"\\n\".join(schema_lines).strip()\n",
        "\n",
        "\n",
        "def create_chatml_dataset(df: pd.DataFrame) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Create ChatML conversations format dataset directly from DataFrame.\n",
        "    Includes system prompt with SQLite constraints.\n",
        "    \"\"\"\n",
        "    # SQLite-focused system prompt based on constraints from prompts.py\n",
        "    system_prompt = \"\"\"You are an expert SQL developer specializing in SQLite. Generate accurate SQL queries that follow these requirements:\n",
        "\n",
        "SQLITE REQUIREMENTS:\n",
        "1. Use only standard SQLite-compatible SQL syntax\n",
        "2. Avoid PostgreSQL-specific functions like INTERVAL - use date arithmetic instead\n",
        "3. Use SQLite date functions: date(), datetime(), julianday() for date calculations\n",
        "4. For \"recent month\" use: WHERE date_column >= date((SELECT MAX(date_column) FROM table_name), '-1 month')\n",
        "5. For \"past 30 days\" use: WHERE date_column >= date((SELECT MAX(date_column) FROM table_name), '-30 days')\n",
        "6. For rolling averages, use window functions or subqueries\n",
        "7. Use MAX(appropriate_date_column) to find the most recent date\n",
        "8. Use proper SQLite column types: INTEGER, TEXT, REAL, BLOB\n",
        "9. Handle foreign key relationships correctly with proper JOIN syntax\n",
        "\n",
        "QUERY STANDARDS:\n",
        "- Write clear, efficient queries\n",
        "- Use appropriate aggregation functions (COUNT, SUM, AVG, MAX, MIN)\n",
        "- Include proper GROUP BY and ORDER BY clauses when needed\n",
        "- Use table aliases for readability in complex queries\"\"\"\n",
        "\n",
        "    chatml_data = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating ChatML dataset\"):\n",
        "        # Skip invalid entries\n",
        "        if not row[\"is_valid\"]:\n",
        "            continue\n",
        "\n",
        "        # Get table metadata for this database\n",
        "        metadata = table_metadata(row[\"db_path\"])\n",
        "        schema_text = format_schema_for_chat(metadata)\n",
        "\n",
        "        # Create user message with schema and question\n",
        "        user_content = f\"Database Schema:\\n{schema_text}\\n\\nQuestion: {row['question']}\"\n",
        "\n",
        "        # Create ChatML conversation with system prompt\n",
        "        chatml_entry = {\n",
        "            \"conversations\": [\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content},\n",
        "                {\"role\": \"assistant\", \"content\": row[\"query\"]},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        chatml_data.append(chatml_entry)\n",
        "\n",
        "    return chatml_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDoJswpY4V-P"
      },
      "source": [
        "Now that we've created our utilities, let's complete our chatml dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9c898g2A_hc"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[df.is_valid]\n",
        "train_df, test_df = train_test_split(\n",
        "    df_filtered, test_size=0.1, random_state=42, stratify=df_filtered.db_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-3mSkplA_hc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zkKrLVDvIW8"
      },
      "outputs": [],
      "source": [
        "# Create the ChatML format dataset for Axolotl\n",
        "print(\"Creating ChatML format dataset for Axolotl...\")\n",
        "train_chatml_dataset = create_chatml_dataset(train_df)\n",
        "eval_chatml_dataset = create_chatml_dataset(test_df)\n",
        "\n",
        "print(f\"Created {len(train_chatml_dataset)} ChatML training examples\")\n",
        "print(f\"Created {len(eval_chatml_dataset)} ChatML evaluation examples\")\n",
        "\n",
        "# Save to JSONL file for Axolotl\n",
        "train_chatml_output_file = \"chatml_training_data.jsonl\"\n",
        "eval_chatml_output_file = \"chatml_evaluation_data.jsonl\"\n",
        "\n",
        "with open(train_chatml_output_file, \"w\") as f:\n",
        "    for entry in train_chatml_dataset:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "print(f\"Saved ChatML training data to {train_chatml_output_file}\")\n",
        "\n",
        "with open(eval_chatml_output_file, \"w\") as f:\n",
        "    for entry in eval_chatml_dataset:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "\n",
        "print(f\"Saved ChatML evaluation data to {eval_chatml_output_file}\")\n",
        "\n",
        "# Display a sample ChatML entry\n",
        "print(\"\\nSample ChatML training entry:\")\n",
        "print(json.dumps(train_chatml_dataset[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qBO2ozuHvO0i"
      },
      "outputs": [],
      "source": [
        "# Note: must be connected to at least an L4 gpu (colab or other) to use flash-attn\n",
        "!uv pip install -Uqqq packaging setuptools wheel ninja\n",
        "!uv pip install -qqq --no-build-isolation \"axolotl[flash-attn,deepspeed]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "30RQ8n4Tzf11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define file URLs and local filenames\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_evaluation_data.jsonl\",\n",
        "    \"https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_training_data.jsonl\",\n",
        "]\n",
        "filenames = [\n",
        "    \"chatml_evaluation_data.jsonl\",\n",
        "    \"chatml_training_data.jsonl\",\n",
        "]\n",
        "\n",
        "# Download files if they don't exist\n",
        "for url, filename in zip(urls, filenames):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        !wget {url} -O {filename}\n",
        "    else:\n",
        "        print(f\"{filename} already exists.\")"
      ],
      "metadata": {
        "id": "AieJHTf-BvWB",
        "outputId": "9f4de399-3acc-462b-86ef-c1c2599105ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chatml_evaluation_data.jsonl...\n",
            "--2025-06-25 21:39:08--  https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_evaluation_data.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34558 (34K) [text/plain]\n",
            "Saving to: ‘chatml_evaluation_data.jsonl’\n",
            "\n",
            "chatml_evaluation_d 100%[===================>]  33.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-06-25 21:39:09 (34.7 MB/s) - ‘chatml_evaluation_data.jsonl’ saved [34558/34558]\n",
            "\n",
            "Downloading chatml_training_data.jsonl...\n",
            "--2025-06-25 21:39:09--  https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_training_data.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 306621 (299K) [text/plain]\n",
            "Saving to: ‘chatml_training_data.jsonl’\n",
            "\n",
            "chatml_training_dat 100%[===================>] 299.43K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-06-25 21:39:09 (65.5 MB/s) - ‘chatml_training_data.jsonl’ saved [306621/306621]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8kFUIFR6Hbi",
        "outputId": "4e1c1623-2945-4dc1-ab71-4bbaba3660cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting axolotl.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile axolotl.yaml\n",
        "base_model: NousResearch/Llama-3.2-1B\n",
        "\n",
        "load_in_8bit: true\n",
        "load_in_4bit: false\n",
        "strict: false\n",
        "adapter: lora\n",
        "# Added for bitsandbytes configuration\n",
        "# bnb_4bit_use_double_quant: true\n",
        "\n",
        "\n",
        "# Data config\n",
        "chat_template: llama3\n",
        "datasets:\n",
        "  - path: chatml_training_data.jsonl\n",
        "    type: chat_template\n",
        "    field_messages: conversations\n",
        "dataset_prepared_path: last_run_prepared\n",
        "\n",
        "test_datasets:\n",
        "  - path: chatml_evaluation_data.jsonl\n",
        "    type: chat_template\n",
        "    field_messages: conversations\n",
        "    split: train\n",
        "\n",
        "output_dir: ./outputs/lora-out\n",
        "\n",
        "sequence_len: 2048\n",
        "sample_packing: true\n",
        "eval_sample_packing: false # with a larger eval dataset, we would do this, but we don't have a large enough one today.\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "lora_target_modules:\n",
        "  - gate_proj\n",
        "  - down_proj\n",
        "  - up_proj\n",
        "  - q_proj\n",
        "  - v_proj\n",
        "  - k_proj\n",
        "  - o_proj\n",
        "\n",
        "wandb_project:\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "gradient_accumulation_steps: 4\n",
        "micro_batch_size: 2\n",
        "num_epochs: 1\n",
        "optimizer: adamw_bnb_8bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: auto\n",
        "fp16:\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention: true\n",
        "\n",
        "loss_watchdog_threshold: 5.0\n",
        "loss_watchdog_patience: 3\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch: 4\n",
        "eval_table_size:\n",
        "eval_max_new_tokens: 128\n",
        "saves_per_epoch: 1\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: <|finetune_right_pad_id|>\n",
        "  eos_token: <|eot_id|>\n",
        "\n",
        "# Added for saving best checkpoint and pushing to Hugging Face Hub\n",
        "save_only_k_checkpoints: 1\n",
        "save_total_limit: 1\n",
        "load_best_model_at_end: true\n",
        "metric_for_best_model: eval_loss # Or any other metric you want to track\n",
        "greater_is_better: false # True if the metric should be maximized, False if minimized\n",
        "\n",
        "# Push to Hugging Face Hub\n",
        "# push_to_hub: false\n",
        "# hub_model_id: your_huggingface_username/your_model_name # Replace with your desired repo ID\n",
        "# hub_private_repo: false # Set to true if you want a private repo\n",
        "# hub_always_push: false\n",
        "# hub_strategy: every_save # \"end\" to push only at the end of training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the datasets\n",
        "!axolotl preprocess axolotl.yaml"
      ],
      "metadata": {
        "id": "0fLmRDqOCTIS",
        "outputId": "fa74fa29-cf12-45ff-c69a-b06a430a89da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-25 21:43:59.904258: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-25 21:43:59.921627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887839.942580    6415 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887839.949010    6415 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-25 21:43:59.970356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-06-25 21:44:05,019] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:6415] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
            "[2025-06-25 21:44:05,357] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:6415] [RANK:0] cuda memory usage baseline: 0.000GB (+0.336GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "[2025-06-25 21:44:07,060] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:6415] [RANK:0] Unable to find prepared dataset in last_run_prepared/7ba8589d17aa28a57c086c50105c21e8\u001b[39m\n",
            "[2025-06-25 21:44:07,060] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:6415] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "[2025-06-25 21:44:07,759] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:6415] [RANK:0] Loading dataset: chatml_training_data.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-06-25 21:44:07,785] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:6415] [RANK:0] Using chat template:\n",
            "---\n",
            "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 135/135 [00:03<00:00, 38.91 examples/s]\n",
            "[2025-06-25 21:44:11,694] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:6415] [RANK:0] min_input_len: 465\u001b[39m\n",
            "[2025-06-25 21:44:11,694] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:6415] [RANK:0] max_input_len: 633\u001b[39m\n",
            "Dropping Long Sequences (num_proc=12): 100% 135/135 [00:00<00:00, 823.92 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=12): 100% 135/135 [00:00<00:00, 714.64 examples/s] \n",
            "Add position_id column (Sample Packing) (num_proc=12): 100% 135/135 [00:00<00:00, 728.93 examples/s] \n",
            "Saving the dataset (1/1 shards): 100% 135/135 [00:00<00:00, 13491.97 examples/s]\n",
            "[2025-06-25 21:44:14,743] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:6415] [RANK:0] Unable to find prepared dataset in last_run_prepared/ef8e57ca0db555d5afeed025b7bdb888\u001b[39m\n",
            "[2025-06-25 21:44:14,743] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:6415] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "[2025-06-25 21:44:15,432] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:6415] [RANK:0] Loading dataset: chatml_evaluation_data.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-06-25 21:44:15,457] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:6415] [RANK:0] Using chat template:\n",
            "---\n",
            "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 15/15 [00:03<00:00,  3.87 examples/s]\n",
            "[2025-06-25 21:44:19,787] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:6415] [RANK:0] min_input_len: 484\u001b[39m\n",
            "[2025-06-25 21:44:19,787] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:6415] [RANK:0] max_input_len: 606\u001b[39m\n",
            "Dropping Long Sequences (num_proc=12): 100% 15/15 [00:00<00:00, 89.99 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=12): 100% 15/15 [00:00<00:00, 74.62 examples/s]\n",
            "Add position_id column (Sample Packing) (num_proc=12): 100% 15/15 [00:00<00:00, 78.53 examples/s] \n",
            "Saving the dataset (1/1 shards): 100% 15/15 [00:00<00:00, 1790.65 examples/s]\n",
            "2025-06-25 21:44:27.448746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887867.470145    7056 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887867.476687    7056 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:44:39.913250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887879.933864    7151 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887879.940206    7151 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:44:51.778116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887891.798770    7238 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887891.805127    7238 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:45:03.639750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887903.661141    7331 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887903.667606    7331 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:45:15.452816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887915.473661    7420 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887915.480026    7420 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:45:27.405379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887927.426497    7511 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887927.432965    7511 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:45:39.319079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887939.339955    7600 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887939.346273    7600 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:45:51.111205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887951.131692    7691 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887951.137960    7691 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:46:02.977631: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887962.998544    7778 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887963.004952    7778 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m[2025-06-25 21:46:10,238] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:6415] [RANK:0] gather_len_batches: [19]\u001b[39m\n",
            "[2025-06-25 21:46:10,238] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:6415] [RANK:0] Maximum number of steps set at 4\u001b[39m\n",
            "[2025-06-25 21:46:10,238] [INFO] [axolotl.common.datasets.load_datasets:74] [PID:6415] [RANK:0] check_dataset_labels...\u001b[39m\n",
            "[2025-06-25 21:46:10,246] [INFO] [axolotl.utils.tokenization.check_example_labels:44] [PID:6415] [RANK:0] \u001b[31m<|begin_of_text|>\u001b[0m\u001b[97m(-100, 128000)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31msystem\u001b[0m\u001b[97m(-100, 9125)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m expert\u001b[0m\u001b[97m(-100, 6335)\u001b[0m \u001b[31m SQL\u001b[0m\u001b[97m(-100, 8029)\u001b[0m \u001b[31m developer\u001b[0m\u001b[97m(-100, 16131)\u001b[0m \u001b[31m specializing\u001b[0m\u001b[97m(-100, 58394)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Generate\u001b[0m\u001b[97m(-100, 20400)\u001b[0m \u001b[31m accurate\u001b[0m\u001b[97m(-100, 13687)\u001b[0m \u001b[31m SQL\u001b[0m\u001b[97m(-100, 8029)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m that\u001b[0m\u001b[97m(-100, 430)\u001b[0m \u001b[31m follow\u001b[0m\u001b[97m(-100, 1833)\u001b[0m \u001b[31m these\u001b[0m\u001b[97m(-100, 1521)\u001b[0m \u001b[31m requirements\u001b[0m\u001b[97m(-100, 8670)\u001b[0m \u001b[31m:\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1473)\u001b[0m \u001b[31mSQL\u001b[0m\u001b[97m(-100, 6827)\u001b[0m \u001b[31mITE\u001b[0m\u001b[97m(-100, 6119)\u001b[0m \u001b[31m REQUIRE\u001b[0m\u001b[97m(-100, 29072)\u001b[0m \u001b[31mMENTS\u001b[0m\u001b[97m(-100, 29863)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m only\u001b[0m\u001b[97m(-100, 1193)\u001b[0m \u001b[31m standard\u001b[0m\u001b[97m(-100, 5410)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m-compatible\u001b[0m\u001b[97m(-100, 81315)\u001b[0m \u001b[31m SQL\u001b[0m\u001b[97m(-100, 8029)\u001b[0m \u001b[31m syntax\u001b[0m\u001b[97m(-100, 20047)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m2\u001b[0m\u001b[97m(-100, 17)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Avoid\u001b[0m\u001b[97m(-100, 35106)\u001b[0m \u001b[31m PostgreSQL\u001b[0m\u001b[97m(-100, 74701)\u001b[0m \u001b[31m-specific\u001b[0m\u001b[97m(-100, 19440)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m like\u001b[0m\u001b[97m(-100, 1093)\u001b[0m \u001b[31m INTERVAL\u001b[0m\u001b[97m(-100, 92243)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m arithmetic\u001b[0m\u001b[97m(-100, 35884)\u001b[0m \u001b[31m instead\u001b[0m\u001b[97m(-100, 4619)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m3\u001b[0m\u001b[97m(-100, 18)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m(),\u001b[0m\u001b[97m(-100, 1535)\u001b[0m \u001b[31m datetime\u001b[0m\u001b[97m(-100, 9050)\u001b[0m \u001b[31m(),\u001b[0m\u001b[97m(-100, 1535)\u001b[0m \u001b[31m j\u001b[0m\u001b[97m(-100, 503)\u001b[0m \u001b[31muli\u001b[0m\u001b[97m(-100, 24520)\u001b[0m \u001b[31mand\u001b[0m\u001b[97m(-100, 438)\u001b[0m \u001b[31may\u001b[0m\u001b[97m(-100, 352)\u001b[0m \u001b[31m()\u001b[0m\u001b[97m(-100, 368)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m calculations\u001b[0m\u001b[97m(-100, 29217)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m4\u001b[0m\u001b[97m(-100, 19)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m For\u001b[0m\u001b[97m(-100, 1789)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrecent\u001b[0m\u001b[97m(-100, 47743)\u001b[0m \u001b[31m month\u001b[0m\u001b[97m(-100, 2305)\u001b[0m \u001b[31m\"\u001b[0m\u001b[97m(-100, 1)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m WHERE\u001b[0m\u001b[97m(-100, 5401)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m >=\u001b[0m\u001b[97m(-100, 2669)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m((\u001b[0m\u001b[97m(-100, 1209)\u001b[0m \u001b[31mSELECT\u001b[0m\u001b[97m(-100, 4963)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m(date\u001b[0m\u001b[97m(-100, 12237)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m FROM\u001b[0m\u001b[97m(-100, 4393)\u001b[0m \u001b[31m table\u001b[0m\u001b[97m(-100, 2007)\u001b[0m \u001b[31m_name\u001b[0m\u001b[97m(-100, 1292)\u001b[0m \u001b[31m),\u001b[0m\u001b[97m(-100, 705)\u001b[0m \u001b[31m '-\u001b[0m\u001b[97m(-100, 7944)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m month\u001b[0m\u001b[97m(-100, 2305)\u001b[0m \u001b[31m')\n",
            "\u001b[0m\u001b[97m(-100, 1329)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m For\u001b[0m\u001b[97m(-100, 1789)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mpast\u001b[0m\u001b[97m(-100, 53520)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m30\u001b[0m\u001b[97m(-100, 966)\u001b[0m \u001b[31m days\u001b[0m\u001b[97m(-100, 2919)\u001b[0m \u001b[31m\"\u001b[0m\u001b[97m(-100, 1)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m WHERE\u001b[0m\u001b[97m(-100, 5401)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m >=\u001b[0m\u001b[97m(-100, 2669)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m((\u001b[0m\u001b[97m(-100, 1209)\u001b[0m \u001b[31mSELECT\u001b[0m\u001b[97m(-100, 4963)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m(date\u001b[0m\u001b[97m(-100, 12237)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m FROM\u001b[0m\u001b[97m(-100, 4393)\u001b[0m \u001b[31m table\u001b[0m\u001b[97m(-100, 2007)\u001b[0m \u001b[31m_name\u001b[0m\u001b[97m(-100, 1292)\u001b[0m \u001b[31m),\u001b[0m\u001b[97m(-100, 705)\u001b[0m \u001b[31m '-\u001b[0m\u001b[97m(-100, 7944)\u001b[0m \u001b[31m30\u001b[0m\u001b[97m(-100, 966)\u001b[0m \u001b[31m days\u001b[0m\u001b[97m(-100, 2919)\u001b[0m \u001b[31m')\n",
            "\u001b[0m\u001b[97m(-100, 1329)\u001b[0m \u001b[31m6\u001b[0m\u001b[97m(-100, 21)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m For\u001b[0m\u001b[97m(-100, 1789)\u001b[0m \u001b[31m rolling\u001b[0m\u001b[97m(-100, 20700)\u001b[0m \u001b[31m averages\u001b[0m\u001b[97m(-100, 49920)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m window\u001b[0m\u001b[97m(-100, 3321)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m sub\u001b[0m\u001b[97m(-100, 1207)\u001b[0m \u001b[31mqueries\u001b[0m\u001b[97m(-100, 43935)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m7\u001b[0m\u001b[97m(-100, 22)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m(app\u001b[0m\u001b[97m(-100, 11718)\u001b[0m \u001b[31mropriate\u001b[0m\u001b[97m(-100, 25264)\u001b[0m \u001b[31m_date\u001b[0m\u001b[97m(-100, 4257)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m find\u001b[0m\u001b[97m(-100, 1505)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m most\u001b[0m\u001b[97m(-100, 1455)\u001b[0m \u001b[31m recent\u001b[0m\u001b[97m(-100, 3293)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m8\u001b[0m\u001b[97m(-100, 23)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m proper\u001b[0m\u001b[97m(-100, 6300)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m column\u001b[0m\u001b[97m(-100, 3330)\u001b[0m \u001b[31m types\u001b[0m\u001b[97m(-100, 4595)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m INTEGER\u001b[0m\u001b[97m(-100, 31481)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m TEXT\u001b[0m\u001b[97m(-100, 16139)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m REAL\u001b[0m\u001b[97m(-100, 26339)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m B\u001b[0m\u001b[97m(-100, 426)\u001b[0m \u001b[31mLOB\u001b[0m\u001b[97m(-100, 10911)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m9\u001b[0m\u001b[97m(-100, 24)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Handle\u001b[0m\u001b[97m(-100, 14078)\u001b[0m \u001b[31m foreign\u001b[0m\u001b[97m(-100, 7362)\u001b[0m \u001b[31m key\u001b[0m\u001b[97m(-100, 1401)\u001b[0m \u001b[31m relationships\u001b[0m\u001b[97m(-100, 12135)\u001b[0m \u001b[31m correctly\u001b[0m\u001b[97m(-100, 12722)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m proper\u001b[0m\u001b[97m(-100, 6300)\u001b[0m \u001b[31m JOIN\u001b[0m\u001b[97m(-100, 13369)\u001b[0m \u001b[31m syntax\u001b[0m\u001b[97m(-100, 20047)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mQUERY\u001b[0m\u001b[97m(-100, 42119)\u001b[0m \u001b[31m ST\u001b[0m\u001b[97m(-100, 4015)\u001b[0m \u001b[31mAND\u001b[0m\u001b[97m(-100, 4064)\u001b[0m \u001b[31mARDS\u001b[0m\u001b[97m(-100, 60994)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Write\u001b[0m\u001b[97m(-100, 9842)\u001b[0m \u001b[31m clear\u001b[0m\u001b[97m(-100, 2867)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m efficient\u001b[0m\u001b[97m(-100, 11297)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m appropriate\u001b[0m\u001b[97m(-100, 8475)\u001b[0m \u001b[31m aggregation\u001b[0m\u001b[97m(-100, 52729)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mCOUNT\u001b[0m\u001b[97m(-100, 39243)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m SUM\u001b[0m\u001b[97m(-100, 31835)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m AVG\u001b[0m\u001b[97m(-100, 71514)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m MIN\u001b[0m\u001b[97m(-100, 17116)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Include\u001b[0m\u001b[97m(-100, 30834)\u001b[0m \u001b[31m proper\u001b[0m\u001b[97m(-100, 6300)\u001b[0m \u001b[31m GROUP\u001b[0m\u001b[97m(-100, 27968)\u001b[0m \u001b[31m BY\u001b[0m\u001b[97m(-100, 7866)\u001b[0m \u001b[31m and\u001b[0m\u001b[97m(-100, 323)\u001b[0m \u001b[31m ORDER\u001b[0m\u001b[97m(-100, 15888)\u001b[0m \u001b[31m BY\u001b[0m\u001b[97m(-100, 7866)\u001b[0m \u001b[31m clauses\u001b[0m\u001b[97m(-100, 50198)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m needed\u001b[0m\u001b[97m(-100, 4460)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m table\u001b[0m\u001b[97m(-100, 2007)\u001b[0m \u001b[31m aliases\u001b[0m\u001b[97m(-100, 41486)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m readability\u001b[0m\u001b[97m(-100, 92594)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m complex\u001b[0m\u001b[97m(-100, 6485)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mDatabase\u001b[0m\u001b[97m(-100, 6116)\u001b[0m \u001b[31m Schema\u001b[0m\u001b[97m(-100, 12824)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m customers\u001b[0m\u001b[97m(-100, 6444)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m first\u001b[0m\u001b[97m(-100, 1176)\u001b[0m \u001b[31m_name\u001b[0m\u001b[97m(-100, 1292)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m last\u001b[0m\u001b[97m(-100, 1566)\u001b[0m \u001b[31m_name\u001b[0m\u001b[97m(-100, 1292)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m email\u001b[0m\u001b[97m(-100, 2613)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m phone\u001b[0m\u001b[97m(-100, 4641)\u001b[0m \u001b[31m_number\u001b[0m\u001b[97m(-100, 5617)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m locations\u001b[0m\u001b[97m(-100, 10687)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m name\u001b[0m\u001b[97m(-100, 836)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m city\u001b[0m\u001b[97m(-100, 3363)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m state\u001b[0m\u001b[97m(-100, 1614)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m zip\u001b[0m\u001b[97m(-100, 10521)\u001b[0m \u001b[31m_code\u001b[0m\u001b[97m(-100, 4229)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m rentals\u001b[0m\u001b[97m(-100, 48104)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m vehicle\u001b[0m\u001b[97m(-100, 7458)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m start\u001b[0m\u001b[97m(-100, 1212)\u001b[0m \u001b[31m_date\u001b[0m\u001b[97m(-100, 4257)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mTIM\u001b[0m\u001b[97m(-100, 35248)\u001b[0m \u001b[31mESTAMP\u001b[0m\u001b[97m(-100, 31755)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m end\u001b[0m\u001b[97m(-100, 842)\u001b[0m \u001b[31m_date\u001b[0m\u001b[97m(-100, 4257)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mTIM\u001b[0m\u001b[97m(-100, 35248)\u001b[0m \u001b[31mESTAMP\u001b[0m\u001b[97m(-100, 31755)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m total\u001b[0m\u001b[97m(-100, 2860)\u001b[0m \u001b[31m_cost\u001b[0m\u001b[97m(-100, 16269)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mDOUBLE\u001b[0m\u001b[97m(-100, 78747)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m vehicles\u001b[0m\u001b[97m(-100, 11731)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m make\u001b[0m\u001b[97m(-100, 1304)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m model\u001b[0m\u001b[97m(-100, 1646)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m year\u001b[0m\u001b[97m(-100, 1060)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m color\u001b[0m\u001b[97m(-100, 1933)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m license\u001b[0m\u001b[97m(-100, 5842)\u001b[0m \u001b[31m_plate\u001b[0m\u001b[97m(-100, 80466)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m location\u001b[0m\u001b[97m(-100, 3813)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mQuestion\u001b[0m\u001b[97m(-100, 14924)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m Which\u001b[0m\u001b[97m(-100, 16299)\u001b[0m \u001b[31m location\u001b[0m\u001b[97m(-100, 3813)\u001b[0m \u001b[31m has\u001b[0m\u001b[97m(-100, 706)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m highest\u001b[0m\u001b[97m(-100, 8592)\u001b[0m \u001b[31m average\u001b[0m\u001b[97m(-100, 5578)\u001b[0m \u001b[31m rental\u001b[0m\u001b[97m(-100, 19160)\u001b[0m \u001b[31m cost\u001b[0m\u001b[97m(-100, 2853)\u001b[0m \u001b[31m?\u001b[0m\u001b[97m(-100, 30)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[32mSELECT\u001b[0m\u001b[97m(4963, 4963)\u001b[0m \u001b[32m l\u001b[0m\u001b[97m(326, 326)\u001b[0m \u001b[32m.name\u001b[0m\u001b[97m(2710, 2710)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m AVG\u001b[0m\u001b[97m(71514, 71514)\u001b[0m \u001b[32m(r\u001b[0m\u001b[97m(2666, 2666)\u001b[0m \u001b[32m.total\u001b[0m\u001b[97m(14032, 14032)\u001b[0m \u001b[32m_cost\u001b[0m\u001b[97m(16269, 16269)\u001b[0m \u001b[32m)\u001b[0m\u001b[97m(8, 8)\u001b[0m \u001b[32m AS\u001b[0m\u001b[97m(5871, 5871)\u001b[0m \u001b[32m avg\u001b[0m\u001b[97m(20291, 20291)\u001b[0m \u001b[32m_rent\u001b[0m\u001b[97m(84227, 84227)\u001b[0m \u001b[32mal\u001b[0m\u001b[97m(278, 278)\u001b[0m \u001b[32m_cost\u001b[0m\u001b[97m(16269, 16269)\u001b[0m \u001b[32m FROM\u001b[0m\u001b[97m(4393, 4393)\u001b[0m \u001b[32m locations\u001b[0m\u001b[97m(10687, 10687)\u001b[0m \u001b[32m l\u001b[0m\u001b[97m(326, 326)\u001b[0m \u001b[32m JOIN\u001b[0m\u001b[97m(13369, 13369)\u001b[0m \u001b[32m vehicles\u001b[0m\u001b[97m(11731, 11731)\u001b[0m \u001b[32m v\u001b[0m\u001b[97m(348, 348)\u001b[0m \u001b[32m ON\u001b[0m\u001b[97m(6328, 6328)\u001b[0m \u001b[32m l\u001b[0m\u001b[97m(326, 326)\u001b[0m \u001b[32m.id\u001b[0m\u001b[97m(1801, 1801)\u001b[0m \u001b[32m =\u001b[0m\u001b[97m(284, 284)\u001b[0m \u001b[32m v\u001b[0m\u001b[97m(348, 348)\u001b[0m \u001b[32m.location\u001b[0m\u001b[97m(8383, 8383)\u001b[0m \u001b[32m_id\u001b[0m\u001b[97m(851, 851)\u001b[0m \u001b[32m JOIN\u001b[0m\u001b[97m(13369, 13369)\u001b[0m \u001b[32m rentals\u001b[0m\u001b[97m(48104, 48104)\u001b[0m \u001b[32m r\u001b[0m\u001b[97m(436, 436)\u001b[0m \u001b[32m ON\u001b[0m\u001b[97m(6328, 6328)\u001b[0m \u001b[32m v\u001b[0m\u001b[97m(348, 348)\u001b[0m \u001b[32m.id\u001b[0m\u001b[97m(1801, 1801)\u001b[0m \u001b[32m =\u001b[0m\u001b[97m(284, 284)\u001b[0m \u001b[32m r\u001b[0m\u001b[97m(436, 436)\u001b[0m \u001b[32m.vehicle\u001b[0m\u001b[97m(70701, 70701)\u001b[0m \u001b[32m_id\u001b[0m\u001b[97m(851, 851)\u001b[0m \u001b[32m GROUP\u001b[0m\u001b[97m(27968, 27968)\u001b[0m \u001b[32m BY\u001b[0m\u001b[97m(7866, 7866)\u001b[0m \u001b[32m l\u001b[0m\u001b[97m(326, 326)\u001b[0m \u001b[32m.name\u001b[0m\u001b[97m(2710, 2710)\u001b[0m \u001b[32m ORDER\u001b[0m\u001b[97m(15888, 15888)\u001b[0m \u001b[32m BY\u001b[0m\u001b[97m(7866, 7866)\u001b[0m \u001b[32m avg\u001b[0m\u001b[97m(20291, 20291)\u001b[0m \u001b[32m_rent\u001b[0m\u001b[97m(84227, 84227)\u001b[0m \u001b[32mal\u001b[0m\u001b[97m(278, 278)\u001b[0m \u001b[32m_cost\u001b[0m\u001b[97m(16269, 16269)\u001b[0m \u001b[32m DESC\u001b[0m\u001b[97m(16477, 16477)\u001b[0m \u001b[32m LIMIT\u001b[0m\u001b[97m(10592, 10592)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m;\u001b[0m\u001b[97m(26, 26)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m\u001b[39m\n",
            "[2025-06-25 21:46:10,281] [INFO] [axolotl.utils.tokenization.check_example_labels:45] [PID:6415] [RANK:0] \n",
            "\n",
            "\n",
            "\u001b[39m\n",
            "[2025-06-25 21:46:10,281] [INFO] [axolotl.utils.tokenization.check_example_labels:48] [PID:6415] [RANK:0] Total input len: 580\u001b[39m\n",
            "[2025-06-25 21:46:10,281] [INFO] [axolotl.utils.tokenization.check_example_labels:49] [PID:6415] [RANK:0] Count of labels: 53\u001b[39m\n",
            "[2025-06-25 21:46:10,281] [INFO] [axolotl.common.datasets.load_datasets:86] [PID:6415] [RANK:0] printing prompters...\u001b[39m\n",
            "[2025-06-25 21:46:10,281] [INFO] [axolotl.common.datasets.load_datasets:88] [PID:6415] [RANK:0] Pre-tokenized or custom dataset types are unsupported for logging\u001b[39m\n",
            "We detected that you are using `from_pretrained` with a meta device context manager or `torch.set_default_device('meta')`\n",
            "This is an anti-pattern and will raise an Error in version v4.53\n",
            "If you want to initialize a model on the meta device, use the context manager or global device with `from_config`, or `ModelClass(config)`\n",
            "model.safetensors: 100% 2.47G/2.47G [00:10<00:00, 238MB/s]\n",
            "generation_config.json: 100% 186/186 [00:00<00:00, 1.44MB/s]\n",
            "[2025-06-25 21:46:23,390] [INFO] [axolotl.cli.preprocess.do_preprocess:75] [PID:6415] [RANK:0] \u001b[32mSuccess! Preprocessed data path: `dataset_prepared_path: last_run_prepared`\u001b[39m\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWb-L0YfvIW9",
        "outputId": "1fcdd546-402e-4ff7-e305-26922857686f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-25 21:46:38.548538: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-25 21:46:38.565938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750887998.587018    8159 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750887998.593477    8159 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-25 21:46:38.614836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-06-25 21:46:54.336067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888014.357119    8286 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888014.363512    8286 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-06-25 21:46:58,733] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:8286] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
            "[2025-06-25 21:46:59,114] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:8286] [RANK:0] cuda memory usage baseline: 0.000GB (+0.336GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "[2025-06-25 21:47:00,789] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:461] [PID:8286] [RANK:0] Loading prepared dataset from disk at last_run_prepared/7ba8589d17aa28a57c086c50105c21e8...\u001b[39m\n",
            "[2025-06-25 21:47:00,794] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:461] [PID:8286] [RANK:0] Loading prepared dataset from disk at last_run_prepared/ef8e57ca0db555d5afeed025b7bdb888...\u001b[39m\n",
            "2025-06-25 21:47:05.914028: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888025.935045    8361 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888025.941451    8361 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:47:17.836082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888037.856654    8416 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888037.862908    8416 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:47:29.806133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888049.827069    8469 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888049.833466    8469 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:47:41.824621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888061.844978    8524 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888061.851217    8524 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:47:53.808367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888073.828952    8579 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888073.835231    8579 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:48:05.753444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888085.774093    8636 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888085.780425    8636 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:48:17.726778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888097.747198    8691 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888097.753377    8691 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:48:29.661286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888109.682065    8750 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888109.688481    8750 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:48:41.586148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888121.607754    8807 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888121.614324    8807 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m[2025-06-25 21:48:48,434] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:8286] [RANK:0] gather_len_batches: [19]\u001b[39m\n",
            "[2025-06-25 21:48:48,434] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:8286] [RANK:0] Maximum number of steps set at 4\u001b[39m\n",
            "[2025-06-25 21:48:55,660] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:8286] [RANK:0] cuda memory usage after model load: 1.408GB (+0.090GB cache, +0.520GB misc)\u001b[39m\n",
            "[2025-06-25 21:48:55,697] [INFO] [axolotl.loaders.model._prepare_model_for_quantization:762] [PID:8286] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-06-25 21:48:55,699] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:8286] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-06-25 21:48:55,701] [INFO] [axolotl.loaders.adapter.load_lora:82] [PID:8286] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "trainable params: 22,544,384 || all params: 1,258,358,784 || trainable%: 1.7916\n",
            "[2025-06-25 21:48:56,070] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:8286] [RANK:0] cuda memory usage after adapters: 1.492GB (+1.086GB cache, +0.547GB misc)\u001b[39m\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[2025-06-25 21:49:02,558] [INFO] [axolotl.train.save_initial_configs:403] [PID:8286] [RANK:0] Pre-saving adapter config to ./outputs/lora-out...\u001b[39m\n",
            "[2025-06-25 21:49:02,558] [INFO] [axolotl.train.save_initial_configs:407] [PID:8286] [RANK:0] Pre-saving tokenizer to ./outputs/lora-out...\u001b[39m\n",
            "[2025-06-25 21:49:02,776] [INFO] [axolotl.train.save_initial_configs:410] [PID:8286] [RANK:0] Pre-saving model config to ./outputs/lora-out...\u001b[39m\n",
            "[2025-06-25 21:49:02,778] [INFO] [axolotl.train.execute_training:225] [PID:8286] [RANK:0] Starting trainer...\u001b[39m\n",
            "2025-06-25 21:49:08.451764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888148.472851    8960 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888148.479171    8960 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:49:20.633688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888160.654300    9045 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888160.660614    9045 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:49:32.770316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888172.791021    9106 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888172.797347    9106 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:49:44.768118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888184.788600    9163 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888184.794889    9163 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:49:56.848624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888196.869107    9220 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888196.875419    9220 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:50:08.991528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888209.012333    9279 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888209.018655    9279 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:50:21.140073: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888221.160582    9336 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888221.166839    9336 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:50:33.304009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888233.324524    9395 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888233.330949    9395 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:50:45.441536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888245.462444    9450 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888245.468888    9450 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m[2025-06-25 21:50:52,338] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:8286] [RANK:0] gather_len_batches: [19]\u001b[39m\n",
            "  0% 0/4 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.84it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.10it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.62it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:00,  2.14it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.13it/s]\u001b[A\n",
            "                         \n",
            "\u001b[A{'eval_loss': 0.8705242872238159, 'eval_runtime': 4.3651, 'eval_samples_per_second': 3.436, 'eval_steps_per_second': 1.833, 'epoch': 0}\n",
            "  0% 0/4 [00:04<?, ?it/s]\n",
            "100% 7/7 [00:03<00:00,  2.11it/s]\u001b[A\n",
            "                                 \u001b[A2025-06-25 21:51:01.900218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888261.920564    9528 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888261.926743    9528 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-25 21:51:13.981279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750888274.001743    9583 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750888274.008017    9583 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "{'loss': 1.0151, 'grad_norm': 0.949002206325531, 'learning_rate': 0.0, 'epoch': 0.21}\n",
            " 25% 1/4 [00:34<01:43, 34.54s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.11it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.52it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.05it/s]\u001b[A\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 0.8705242872238159, 'eval_runtime': 3.5927, 'eval_samples_per_second': 4.175, 'eval_steps_per_second': 2.227, 'epoch': 0.21}\n",
            " 25% 1/4 [00:38<01:43, 34.54s/it]\n",
            "100% 7/7 [00:03<00:00,  2.06it/s]\u001b[A\n",
            "                                 \u001b[A[2025-06-25 21:51:36,379] [INFO] [axolotl.utils.callbacks.log_gpu_memory_usage:107] [PID:8286] [RANK:0] cuda memory usage while training: 1.555GB (+7.527GB cache, +0.581GB misc)\u001b[39m\n",
            "{'loss': 0.9457, 'grad_norm': 0.8571003675460815, 'learning_rate': 2e-05, 'epoch': 0.42}\n",
            " 50% 2/4 [00:43<00:39, 19.77s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.10it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.89it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.51it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  2.00it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.04it/s]\u001b[A\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 0.8674715757369995, 'eval_runtime': 3.6121, 'eval_samples_per_second': 4.153, 'eval_steps_per_second': 2.215, 'epoch': 0.42}\n",
            " 50% 2/4 [00:47<00:39, 19.77s/it]\n",
            "100% 7/7 [00:03<00:00,  2.04it/s]\u001b[A\n",
            "{'loss': 0.9592, 'grad_norm': 0.796516478061676, 'learning_rate': 4e-05, 'epoch': 0.63}\n",
            " 75% 3/4 [00:53<00:15, 15.08s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.12it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.51it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:00,  2.00it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.04it/s]\u001b[A\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 0.8588968515396118, 'eval_runtime': 3.6081, 'eval_samples_per_second': 4.157, 'eval_steps_per_second': 2.217, 'epoch': 0.63}\n",
            " 75% 3/4 [00:57<00:15, 15.08s/it]\n",
            "100% 7/7 [00:03<00:00,  2.05it/s]\u001b[A\n",
            "{'loss': 0.9714, 'grad_norm': 0.8878889679908752, 'learning_rate': 6e-05, 'epoch': 0.84}\n",
            "100% 4/4 [01:02<00:00, 12.87s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.08it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.50it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.03it/s]\u001b[A\n",
            "                                 \n",
            "\u001b[A{'eval_loss': 0.828676164150238, 'eval_runtime': 3.6214, 'eval_samples_per_second': 4.142, 'eval_steps_per_second': 2.209, 'epoch': 0.84}\n",
            "100% 4/4 [01:06<00:00, 12.87s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'train_runtime': 67.6922, 'train_samples_per_second': 0.473, 'train_steps_per_second': 0.059, 'train_loss': 0.9728585183620453, 'epoch': 0.84}\n",
            "100% 4/4 [01:07<00:00, 16.92s/it]\n",
            "[2025-06-25 21:52:00,098] [INFO] [axolotl.train.save_trained_model:244] [PID:8286] [RANK:0] Training completed! Saving trained model to ./outputs/lora-out.\u001b[39m\n",
            "[2025-06-25 21:52:00,804] [INFO] [axolotl.train.save_trained_model:341] [PID:8286] [RANK:0] Model successfully saved to ./outputs/lora-out\u001b[39m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "!axolotl train axolotl.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3eFNBvnvIW9"
      },
      "outputs": [],
      "source": [
        "# [optional] merge weights\n",
        "# !python -m axolotl.cli.merge_lora axolotl.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sfmtXqLzvc_",
        "outputId": "a1b46f03-8e36-4e3b-e853-0c5bdb015697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start hashing 8 files.\n",
            "Finished hashing 8 files.\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "adapter_model.safetensors:   0% 0.00/90.2M [00:00<?, ?B/s]\u001b[A\n",
            "adapter_model.safetensors:  18% 16.0M/90.2M [00:00<00:03, 20.5MB/s]\u001b[A\n",
            "adapter_model.safetensors:  53% 48.0M/90.2M [00:00<00:00, 63.0MB/s]\u001b[A\n",
            "adapter_model.safetensors:  71% 64.0M/90.2M [00:01<00:00, 55.8MB/s]\u001b[A\n",
            "adapter_model.safetensors:  89% 80.0M/90.2M [00:01<00:00, 56.5MB/s]\u001b[A\n",
            "adapter_model.safetensors: 96.0MB [00:02, 39.5MB/s]\n",
            " 50% 1/2 [00:02<00:02,  2.81s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:00<00:00, 27.8MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:02, 13.8MB/s]\n",
            "100% 2/2 [00:05<00:00,  2.73s/it]\n",
            "https://huggingface.co/mgfrantz/NousResearch-Llama-3.2-1B-ctme-sql-demo/tree/main/.\n"
          ]
        }
      ],
      "source": [
        "# [optional] upload to hf hub\n",
        "import os\n",
        "\n",
        "username = \"mgfrantz\"\n",
        "repo_name = \"NousResearch-Llama-3.2-1B-ctme-sql-demo\"\n",
        "if not username or not repo_name:\n",
        "    username = input(\"Username: \")\n",
        "    repo_name = input(\"Repo name: \")\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "!rm -r outputs/lora-out/checkpoint-*\n",
        "!huggingface-cli upload {username}/{repo_name} ./outputs/lora-out/ ."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-zAMJDwE781"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}