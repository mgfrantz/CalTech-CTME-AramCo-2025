{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgfrantz/CalTech-CTME-AramCo-2025/blob/main/notebooks/02_fine_tune_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA9sUDBfwiM9"
      },
      "source": [
        "# Part 1: Dataset Preparation\n",
        "\n",
        "## What We're Doing\n",
        "\n",
        "Previously, we created a dataset of question/SQL query pairs and validated them against actual SQLite databases. Now we'll **fine-tune a language model** to accept a SQL schema and a natural language question, then output a correct SQLite query.\n",
        "\n",
        "## Why This Approach Works\n",
        "\n",
        "Fine-tuning allows us to:\n",
        "- Teach the model our specific database schemas and patterns\n",
        "- Improve accuracy on domain-specific SQL queries\n",
        "- Reduce hallucinations by training on validated examples\n",
        "\n",
        "## Dataset Format Strategy\n",
        "\n",
        "The first step is preparing our dataset in the **correct format**. We'll use ChatML format because:\n",
        "\n",
        "1. **Consistency**: Use the same format your base model was trained on (most modern models use chat format)\n",
        "2. **Portability**: This format works across multiple platforms (Axolotl, OpenAI fine-tuning, etc.)\n",
        "3. **Structure**: Clear separation of system instructions, user input, and expected output\n",
        "\n",
        "Our dataset structure:\n",
        "```json\n",
        "{\n",
        "    \"conversations\": [\n",
        "        {\"role\": \"system\", \"content\": \"Expert SQL developer instructions...\"},\n",
        "        {\"role\": \"user\", \"content\": \"Schema: [tables] Question: [user query]\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"SELECT * FROM table WHERE...\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "This 3-message pattern teaches the model:\n",
        "- **System**: How to behave (SQL expert with SQLite constraints)\n",
        "- **User**: What information it receives (schema + question)  \n",
        "- **Assistant**: What we want it to output (correct SQL query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toX4WhNCvIW4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK_4qRtOvIW6"
      },
      "outputs": [],
      "source": [
        "# If running this on colab, make sure to upload the parquet file and update the path.\n",
        "df = pd.read_parquet(\"../output/validated_dataset.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YifRBpdivIW6"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq6CVs-230ot"
      },
      "source": [
        "## Step 1: Schema Extraction\n",
        "\n",
        "To train our model effectively, we need to provide it with database schema information in a readable format.\n",
        "\n",
        "**Why schemas matter**: The model needs to understand:\n",
        "- What tables exist in the database\n",
        "- What columns are in each table  \n",
        "- Data types and constraints (PRIMARY KEY, NOT NULL, etc.)\n",
        "- Relationships between tables\n",
        "\n",
        "Let's create utilities to extract and format this schema information from our SQLite databases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6OvetrTvIW7"
      },
      "outputs": [],
      "source": [
        "# Utilities\n",
        "duckdb.execute(\"\"\"\n",
        "INSTALL sqlite;\n",
        "LOAD sqlite;\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "def query_sqlite(query: str, db_path: str) -> pd.DataFrame:\n",
        "    conn = duckdb.connect(db_path)\n",
        "    return conn.execute(query).fetch_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzeCD_vjvIW7"
      },
      "outputs": [],
      "source": [
        "path = df.db_path.iloc[0]\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlahhsYdvIW7"
      },
      "outputs": [],
      "source": [
        "tables = query_sqlite(\"SHOW TABLES\", path)\n",
        "tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdqZlSqwvIW7"
      },
      "outputs": [],
      "source": [
        "for table in tables.name:\n",
        "    print(table)\n",
        "    display(\n",
        "        t := query_sqlite(f\"DESCRIBE TABLE {table}\", path).dropna(how=\"all\", axis=1)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT4zfNoZvIW8"
      },
      "outputs": [],
      "source": [
        "def table_metadata(db_path: str) -> dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Get metadata for all tables in the database.\n",
        "    \"\"\"\n",
        "    tables = query_sqlite(\"SHOW TABLES\", db_path)\n",
        "    metadata = {}\n",
        "    for table in tables.name:\n",
        "        metadata[table] = query_sqlite(f\"DESCRIBE TABLE {table}\", db_path).dropna(\n",
        "            how=\"all\", axis=1\n",
        "        )\n",
        "    return metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weAvzz0DvIW8"
      },
      "outputs": [],
      "source": [
        "def format_schema_for_chat(metadata: dict[str, pd.DataFrame]) -> str:\n",
        "    \"\"\"\n",
        "    Format table metadata into a readable string for chat training.\n",
        "    \"\"\"\n",
        "    schema_lines = []\n",
        "\n",
        "    for table_name, df in metadata.items():\n",
        "        schema_lines.append(f\"Table: {table_name}\")\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            col_info = f\"  - {row['column_name']} ({row['column_type']}\"\n",
        "            if row[\"key\"] == \"PRI\":\n",
        "                col_info += \", PRIMARY KEY\"\n",
        "            elif pd.notna(row[\"key\"]) and row[\"key\"] != \"None\":\n",
        "                col_info += f\", {row['key']}\"\n",
        "            if row[\"null\"] == \"NO\":\n",
        "                col_info += \", NOT NULL\"\n",
        "            col_info += \")\"\n",
        "            schema_lines.append(col_info)\n",
        "\n",
        "        schema_lines.append(\"\")  # Add blank line between tables\n",
        "\n",
        "    return \"\\n\".join(schema_lines).strip()\n",
        "\n",
        "\n",
        "def create_chatml_dataset(df: pd.DataFrame) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Create ChatML conversations format dataset directly from DataFrame.\n",
        "    Includes system prompt with SQLite constraints.\n",
        "    \"\"\"\n",
        "    # SQLite-focused system prompt based on constraints from prompts.py\n",
        "    system_prompt = \"\"\"You are an expert SQL developer specializing in SQLite. Generate accurate SQL queries that follow these requirements:\n",
        "\n",
        "SQLITE REQUIREMENTS:\n",
        "1. Use only standard SQLite-compatible SQL syntax\n",
        "2. Avoid PostgreSQL-specific functions like INTERVAL - use date arithmetic instead\n",
        "3. Use SQLite date functions: date(), datetime(), julianday() for date calculations\n",
        "4. For \"recent month\" use: WHERE date_column >= date((SELECT MAX(date_column) FROM table_name), '-1 month')\n",
        "5. For \"past 30 days\" use: WHERE date_column >= date((SELECT MAX(date_column) FROM table_name), '-30 days')\n",
        "6. For rolling averages, use window functions or subqueries\n",
        "7. Use MAX(appropriate_date_column) to find the most recent date\n",
        "8. Use proper SQLite column types: INTEGER, TEXT, REAL, BLOB\n",
        "9. Handle foreign key relationships correctly with proper JOIN syntax\n",
        "\n",
        "QUERY STANDARDS:\n",
        "- Write clear, efficient queries\n",
        "- Use appropriate aggregation functions (COUNT, SUM, AVG, MAX, MIN)\n",
        "- Include proper GROUP BY and ORDER BY clauses when needed\n",
        "- Use table aliases for readability in complex queries\"\"\"\n",
        "\n",
        "    chatml_data = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating ChatML dataset\"):\n",
        "        # Skip invalid entries\n",
        "        if not row[\"is_valid\"]:\n",
        "            continue\n",
        "\n",
        "        # Get table metadata for this database\n",
        "        metadata = table_metadata(row[\"db_path\"])\n",
        "        schema_text = format_schema_for_chat(metadata)\n",
        "\n",
        "        # Create user message with schema and question\n",
        "        user_content = f\"Database Schema:\\n{schema_text}\\n\\nQuestion: {row['question']}\"\n",
        "\n",
        "        # Create ChatML conversation with system prompt\n",
        "        chatml_entry = {\n",
        "            \"conversations\": [\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content},\n",
        "                {\"role\": \"assistant\", \"content\": row[\"query\"]},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        chatml_data.append(chatml_entry)\n",
        "\n",
        "    return chatml_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDoJswpY4V-P"
      },
      "source": [
        "## Step 2: Creating the ChatML Dataset\n",
        "\n",
        "Now we'll convert our validated question/query pairs into the ChatML format for fine-tuning.\n",
        "\n",
        "**Key components of our dataset creation**:\n",
        "\n",
        "1. **System Prompt**: Detailed instructions about SQLite syntax and constraints\n",
        "2. **User Message**: Database schema + natural language question\n",
        "3. **Assistant Response**: The validated SQL query\n",
        "\n",
        "**Important notes**:\n",
        "- We only include validated examples (`is_valid=True`)\n",
        "- We stratify the train/test split by database to ensure both sets have representative samples\n",
        "- Each conversation teaches the model one complete SQL generation task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9c898g2A_hc"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[df.is_valid]\n",
        "train_df, test_df = train_test_split(\n",
        "    df_filtered, test_size=0.1, random_state=42, stratify=df_filtered.db_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zkKrLVDvIW8"
      },
      "outputs": [],
      "source": [
        "# Create the ChatML format dataset for Axolotl\n",
        "print(\"Creating ChatML format dataset for Axolotl...\")\n",
        "train_chatml_dataset = create_chatml_dataset(train_df)\n",
        "eval_chatml_dataset = create_chatml_dataset(test_df)\n",
        "\n",
        "print(f\"Created {len(train_chatml_dataset)} ChatML training examples\")\n",
        "print(f\"Created {len(eval_chatml_dataset)} ChatML evaluation examples\")\n",
        "\n",
        "# Save to JSONL file for Axolotl\n",
        "train_chatml_output_file = \"chatml_training_data.jsonl\"\n",
        "eval_chatml_output_file = \"chatml_evaluation_data.jsonl\"\n",
        "\n",
        "with open(train_chatml_output_file, \"w\") as f:\n",
        "    for entry in train_chatml_dataset:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "print(f\"Saved ChatML training data to {train_chatml_output_file}\")\n",
        "\n",
        "with open(eval_chatml_output_file, \"w\") as f:\n",
        "    for entry in eval_chatml_dataset:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "\n",
        "print(f\"Saved ChatML evaluation data to {eval_chatml_output_file}\")\n",
        "\n",
        "# Display a sample ChatML entry\n",
        "print(\"\\nSample ChatML training entry:\")\n",
        "print(json.dumps(train_chatml_dataset[0], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK5yBYkhT2Kk"
      },
      "source": [
        "# Part 2: Fine-tuning with LoRA\n",
        "\n",
        "## What is LoRA?\n",
        "\n",
        "**LoRA (Low-Rank Adaptation)** is an efficient fine-tuning technique that:\n",
        "- Only trains a small number of additional parameters (~1% of the original model)\n",
        "- Maintains the original model weights unchanged\n",
        "- Reduces memory requirements and training time\n",
        "- Produces a small \"adapter\" that can be easily shared and applied\n",
        "\n",
        "## Why Use Google Colab?\n",
        "\n",
        "Fine-tuning requires significant computational resources:\n",
        "- **GPU Memory**: Need at least 8GB+ GPU memory (L4, T4, V100, A100)\n",
        "- **Flash Attention**: Speeds up training and reduces memory usage (L4 and A100 only)\n",
        "- **Cost Effective**: Colab Pro gives access to powerful GPUs without infrastructure setup\n",
        "\n",
        "## Training Strategy\n",
        "\n",
        "We'll use **Axolotl**, a popular fine-tuning framework that:\n",
        "- Handles data preprocessing automatically\n",
        "- Supports various model architectures and adapters\n",
        "- Provides sensible defaults for LoRA training\n",
        "- Integrates with HuggingFace for easy model sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8FzgqmpT2Kk"
      },
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "We need to install Axolotl with Flash Attention support. This installation:\n",
        "- **Requires GPU**: Flash Attention only works on CUDA GPUs\n",
        "- **Takes time**: Compiling Flash Attention can take 5-10 minutes\n",
        "- **Memory intensive**: Make sure you have sufficient GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qBO2ozuHvO0i"
      },
      "outputs": [],
      "source": [
        "# Note: must be connected to at least an L4 gpu (colab or other) to use flash-attn\n",
        "!uv pip install -Uqqq packaging setuptools wheel ninja\n",
        "!uv pip install -qqq --no-build-isolation \"axolotl[flash-attn,deepspeed]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJjTWBffT2Kl"
      },
      "source": [
        "## Step 2: Setup Environment\n",
        "\n",
        "Configure HuggingFace token for model access and downloading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "30RQ8n4Tzf11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_-73FtUT2Kl"
      },
      "source": [
        "## Step 3: Download Training Data\n",
        "\n",
        "Download our prepared ChatML datasets from the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AieJHTf-BvWB",
        "outputId": "83728c09-36d9-4a68-ac2b-a5f7c6ab33e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chatml_evaluation_data.jsonl...\n",
            "--2025-06-26 03:38:23--  https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_evaluation_data.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34558 (34K) [text/plain]\n",
            "Saving to: ‘chatml_evaluation_data.jsonl’\n",
            "\n",
            "chatml_evaluation_d 100%[===================>]  33.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-06-26 03:38:23 (27.8 MB/s) - ‘chatml_evaluation_data.jsonl’ saved [34558/34558]\n",
            "\n",
            "Downloading chatml_training_data.jsonl...\n",
            "--2025-06-26 03:38:23--  https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_training_data.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 306621 (299K) [text/plain]\n",
            "Saving to: ‘chatml_training_data.jsonl’\n",
            "\n",
            "chatml_training_dat 100%[===================>] 299.43K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-06-26 03:38:24 (70.8 MB/s) - ‘chatml_training_data.jsonl’ saved [306621/306621]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define file URLs and local filenames\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_evaluation_data.jsonl\",\n",
        "    \"https://raw.githubusercontent.com/mgfrantz/CalTech-CTME-AramCo-2025/refs/heads/main/notebooks/chatml_training_data.jsonl\",\n",
        "]\n",
        "filenames = [\n",
        "    \"chatml_evaluation_data.jsonl\",\n",
        "    \"chatml_training_data.jsonl\",\n",
        "]\n",
        "\n",
        "# Download files if they don't exist\n",
        "for url, filename in zip(urls, filenames):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        !wget {url} -O {filename}\n",
        "    else:\n",
        "        print(f\"{filename} already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Vi6xIrT2Kl"
      },
      "source": [
        "## Step 4: Configure Training\n",
        "\n",
        "This YAML configuration defines our training setup:\n",
        "\n",
        "**Model Configuration**:\n",
        "- `base_model`: Starting with Llama-3.2-1B (fast to train, good performance)\n",
        "- `load_in_8bit`: Reduces memory usage for training\n",
        "\n",
        "**LoRA Configuration**:\n",
        "- `lora_r`: 32 (rank of adaptation - higher = more parameters but better learning)\n",
        "- `lora_alpha`: 16 (scaling factor)\n",
        "- `lora_target_modules`: Which layers to adapt (all attention and MLP layers)\n",
        "\n",
        "**Training Configuration**:\n",
        "- `num_epochs`: 10 (how many times to see the full dataset)\n",
        "- `learning_rate`: 0.0002 (conservative rate to avoid overfitting)\n",
        "- `micro_batch_size`: 2 (small batches to fit in GPU memory)\n",
        "- `gradient_accumulation_steps`: 4 (effective batch size = 2 × 4 = 8)\n",
        "\n",
        "**Monitoring**:\n",
        "- `evals_per_epoch`: 4 (check validation loss 4 times per epoch)\n",
        "- `saves_per_epoch`: 1 (save checkpoints once per epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8kFUIFR6Hbi",
        "outputId": "a9d23a9f-3e0c-4efd-d5e8-e094b462a9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing axolotl.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile axolotl.yaml\n",
        "# Configure the base model and output directory\n",
        "base_model: NousResearch/Llama-3.2-1B\n",
        "output_dir: ./outputs/lora-out\n",
        "\n",
        "# Lora configuration\n",
        "load_in_8bit: true\n",
        "load_in_4bit: false\n",
        "strict: false\n",
        "adapter: lora\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "lora_target_modules:\n",
        "  - gate_proj\n",
        "  - down_proj\n",
        "  - up_proj\n",
        "  - q_proj\n",
        "  - v_proj\n",
        "  - k_proj\n",
        "  - o_proj\n",
        "\n",
        "\n",
        "# Data configuration\n",
        "chat_template: llama3\n",
        "datasets:\n",
        "  - path: chatml_training_data.jsonl\n",
        "    type: chat_template\n",
        "    field_messages: conversations\n",
        "dataset_prepared_path: last_run_prepared\n",
        "\n",
        "test_datasets:\n",
        "  - path: chatml_evaluation_data.jsonl\n",
        "    type: chat_template\n",
        "    field_messages: conversations\n",
        "    split: train\n",
        "\n",
        "sequence_len: 2048\n",
        "sample_packing: true\n",
        "eval_sample_packing: false # with a larger eval dataset, we would do this, but we don't have a large enough one today.\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "# [optional] weights and biases configuration\n",
        "wandb_project:\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "# Training hyperparameters\n",
        "gradient_accumulation_steps: 4\n",
        "micro_batch_size: 2\n",
        "num_epochs: 10\n",
        "optimizer: adamw_bnb_8bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "# Masking\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: auto\n",
        "fp16:\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention: true\n",
        "\n",
        "loss_watchdog_threshold: 5.0\n",
        "loss_watchdog_patience: 3\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch: 4\n",
        "eval_table_size:\n",
        "eval_max_new_tokens: 128\n",
        "saves_per_epoch: 1\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: <|finetune_right_pad_id|>\n",
        "  eos_token: <|eot_id|>\n",
        "\n",
        "# Added for saving best checkpoint and pushing to Hugging Face Hub\n",
        "save_only_k_checkpoints: 1\n",
        "save_total_limit: 1\n",
        "load_best_model_at_end: true\n",
        "metric_for_best_model: eval_loss # Or any other metric you want to track\n",
        "greater_is_better: false # True if the metric should be maximized, False if minimized\n",
        "\n",
        "# Push to Hugging Face Hub\n",
        "# push_to_hub: false\n",
        "# hub_model_id: your_huggingface_username/your_model_name # Replace with your desired repo ID\n",
        "# hub_private_repo: false # Set to true if you want a private repo\n",
        "# hub_always_push: false\n",
        "# hub_strategy: every_save # \"end\" to push only at the end of training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g58Hqk1T2Kl"
      },
      "source": [
        "## Step 5: Preprocess Data\n",
        "\n",
        "Axolotl preprocesses our JSONL files into its internal format for efficient training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fLmRDqOCTIS",
        "outputId": "39830818-2406-4d1a-bdea-728b249cff9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-26 03:40:00.602220: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-26 03:40:00.619150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909200.640372    3849 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909200.646788    3849 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-26 03:40:00.668254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-06-26 03:40:09,353] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:3849] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
            "config.json: 100% 843/843 [00:00<00:00, 5.72MB/s]\n",
            "[2025-06-26 03:40:09,761] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:3849] [RANK:0] cuda memory usage baseline: 0.000GB (+0.336GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "tokenizer_config.json: 50.5kB [00:00, 147MB/s]\n",
            "tokenizer.json: 9.09MB [00:00, 162MB/s]\n",
            "special_tokens_map.json: 100% 301/301 [00:00<00:00, 2.43MB/s]\n",
            "[2025-06-26 03:40:13,174] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:3849] [RANK:0] Unable to find prepared dataset in last_run_prepared/7ba8589d17aa28a57c086c50105c21e8\u001b[39m\n",
            "[2025-06-26 03:40:13,174] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:3849] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "Generating train split: 135 examples [00:00, 9634.37 examples/s]\n",
            "[2025-06-26 03:40:13,978] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:3849] [RANK:0] Loading dataset: chatml_training_data.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-06-26 03:40:14,013] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:3849] [RANK:0] Using chat template:\n",
            "---\n",
            "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 135/135 [00:03<00:00, 38.59 examples/s]\n",
            "[2025-06-26 03:40:17,951] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:3849] [RANK:0] min_input_len: 465\u001b[39m\n",
            "[2025-06-26 03:40:17,951] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:3849] [RANK:0] max_input_len: 633\u001b[39m\n",
            "Dropping Long Sequences (num_proc=12): 100% 135/135 [00:00<00:00, 759.12 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=12): 100% 135/135 [00:00<00:00, 713.37 examples/s]\n",
            "Add position_id column (Sample Packing) (num_proc=12): 100% 135/135 [00:00<00:00, 695.44 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 135/135 [00:00<00:00, 13402.55 examples/s]\n",
            "[2025-06-26 03:40:21,115] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:3849] [RANK:0] Unable to find prepared dataset in last_run_prepared/ef8e57ca0db555d5afeed025b7bdb888\u001b[39m\n",
            "[2025-06-26 03:40:21,116] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:3849] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "Generating train split: 15 examples [00:00, 7797.07 examples/s]\n",
            "[2025-06-26 03:40:21,823] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:3849] [RANK:0] Loading dataset: chatml_evaluation_data.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
            "[2025-06-26 03:40:21,847] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:3849] [RANK:0] Using chat template:\n",
            "---\n",
            "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "---\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 15/15 [00:03<00:00,  4.03 examples/s]\n",
            "[2025-06-26 03:40:26,055] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:3849] [RANK:0] min_input_len: 484\u001b[39m\n",
            "[2025-06-26 03:40:26,055] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:3849] [RANK:0] max_input_len: 606\u001b[39m\n",
            "Dropping Long Sequences (num_proc=12): 100% 15/15 [00:00<00:00, 90.50 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=12): 100% 15/15 [00:00<00:00, 80.88 examples/s] \n",
            "Add position_id column (Sample Packing) (num_proc=12): 100% 15/15 [00:00<00:00, 79.96 examples/s] \n",
            "Saving the dataset (1/1 shards): 100% 15/15 [00:00<00:00, 1955.26 examples/s]\n",
            "2025-06-26 03:40:33.975383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909233.996932    4532 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909234.003415    4532 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:40:46.770931: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909246.792091    4630 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909246.798650    4630 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:40:58.904052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909258.925986    4721 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909258.932356    4721 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:41:10.865460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909270.886649    4812 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909270.893104    4812 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:41:22.777358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909282.798040    4903 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909282.804591    4903 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:41:34.710750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909294.731386    4996 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909294.737740    4996 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:41:46.757816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909306.778726    5085 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909306.785053    5085 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:41:58.877839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909318.898867    5174 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909318.905210    5174 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:42:10.991051: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909331.012029    5265 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909331.018458    5265 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m[2025-06-26 03:42:18,413] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:3849] [RANK:0] gather_len_batches: [19]\u001b[39m\n",
            "[2025-06-26 03:42:18,414] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:3849] [RANK:0] Maximum number of steps set at 40\u001b[39m\n",
            "[2025-06-26 03:42:18,414] [INFO] [axolotl.common.datasets.load_datasets:74] [PID:3849] [RANK:0] check_dataset_labels...\u001b[39m\n",
            "[2025-06-26 03:42:18,420] [INFO] [axolotl.utils.tokenization.check_example_labels:44] [PID:3849] [RANK:0] \u001b[31m<|begin_of_text|>\u001b[0m\u001b[97m(-100, 128000)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31msystem\u001b[0m\u001b[97m(-100, 9125)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m expert\u001b[0m\u001b[97m(-100, 6335)\u001b[0m \u001b[31m SQL\u001b[0m\u001b[97m(-100, 8029)\u001b[0m \u001b[31m developer\u001b[0m\u001b[97m(-100, 16131)\u001b[0m \u001b[31m specializing\u001b[0m\u001b[97m(-100, 58394)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Generate\u001b[0m\u001b[97m(-100, 20400)\u001b[0m \u001b[31m accurate\u001b[0m\u001b[97m(-100, 13687)\u001b[0m \u001b[31m SQL\u001b[0m\u001b[97m(-100, 8029)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m that\u001b[0m\u001b[97m(-100, 430)\u001b[0m \u001b[31m follow\u001b[0m\u001b[97m(-100, 1833)\u001b[0m \u001b[31m these\u001b[0m\u001b[97m(-100, 1521)\u001b[0m \u001b[31m requirements\u001b[0m\u001b[97m(-100, 8670)\u001b[0m \u001b[31m:\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1473)\u001b[0m \u001b[31mSQL\u001b[0m\u001b[97m(-100, 6827)\u001b[0m \u001b[31mITE\u001b[0m\u001b[97m(-100, 6119)\u001b[0m \u001b[31m REQUIRE\u001b[0m\u001b[97m(-100, 29072)\u001b[0m \u001b[31mMENTS\u001b[0m\u001b[97m(-100, 29863)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m only\u001b[0m\u001b[97m(-100, 1193)\u001b[0m \u001b[31m standard\u001b[0m\u001b[97m(-100, 5410)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m-compatible\u001b[0m\u001b[97m(-100, 81315)\u001b[0m \u001b[31m SQL\u001b[0m\u001b[97m(-100, 8029)\u001b[0m \u001b[31m syntax\u001b[0m\u001b[97m(-100, 20047)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m2\u001b[0m\u001b[97m(-100, 17)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Avoid\u001b[0m\u001b[97m(-100, 35106)\u001b[0m \u001b[31m PostgreSQL\u001b[0m\u001b[97m(-100, 74701)\u001b[0m \u001b[31m-specific\u001b[0m\u001b[97m(-100, 19440)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m like\u001b[0m\u001b[97m(-100, 1093)\u001b[0m \u001b[31m INTERVAL\u001b[0m\u001b[97m(-100, 92243)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m arithmetic\u001b[0m\u001b[97m(-100, 35884)\u001b[0m \u001b[31m instead\u001b[0m\u001b[97m(-100, 4619)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m3\u001b[0m\u001b[97m(-100, 18)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m(),\u001b[0m\u001b[97m(-100, 1535)\u001b[0m \u001b[31m datetime\u001b[0m\u001b[97m(-100, 9050)\u001b[0m \u001b[31m(),\u001b[0m\u001b[97m(-100, 1535)\u001b[0m \u001b[31m j\u001b[0m\u001b[97m(-100, 503)\u001b[0m \u001b[31muli\u001b[0m\u001b[97m(-100, 24520)\u001b[0m \u001b[31mand\u001b[0m\u001b[97m(-100, 438)\u001b[0m \u001b[31may\u001b[0m\u001b[97m(-100, 352)\u001b[0m \u001b[31m()\u001b[0m\u001b[97m(-100, 368)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m calculations\u001b[0m\u001b[97m(-100, 29217)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m4\u001b[0m\u001b[97m(-100, 19)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m For\u001b[0m\u001b[97m(-100, 1789)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrecent\u001b[0m\u001b[97m(-100, 47743)\u001b[0m \u001b[31m month\u001b[0m\u001b[97m(-100, 2305)\u001b[0m \u001b[31m\"\u001b[0m\u001b[97m(-100, 1)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m WHERE\u001b[0m\u001b[97m(-100, 5401)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m >=\u001b[0m\u001b[97m(-100, 2669)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m((\u001b[0m\u001b[97m(-100, 1209)\u001b[0m \u001b[31mSELECT\u001b[0m\u001b[97m(-100, 4963)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m(date\u001b[0m\u001b[97m(-100, 12237)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m FROM\u001b[0m\u001b[97m(-100, 4393)\u001b[0m \u001b[31m table\u001b[0m\u001b[97m(-100, 2007)\u001b[0m \u001b[31m_name\u001b[0m\u001b[97m(-100, 1292)\u001b[0m \u001b[31m),\u001b[0m\u001b[97m(-100, 705)\u001b[0m \u001b[31m '-\u001b[0m\u001b[97m(-100, 7944)\u001b[0m \u001b[31m1\u001b[0m\u001b[97m(-100, 16)\u001b[0m \u001b[31m month\u001b[0m\u001b[97m(-100, 2305)\u001b[0m \u001b[31m')\n",
            "\u001b[0m\u001b[97m(-100, 1329)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m For\u001b[0m\u001b[97m(-100, 1789)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mpast\u001b[0m\u001b[97m(-100, 53520)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m30\u001b[0m\u001b[97m(-100, 966)\u001b[0m \u001b[31m days\u001b[0m\u001b[97m(-100, 2919)\u001b[0m \u001b[31m\"\u001b[0m\u001b[97m(-100, 1)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m WHERE\u001b[0m\u001b[97m(-100, 5401)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m >=\u001b[0m\u001b[97m(-100, 2669)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m((\u001b[0m\u001b[97m(-100, 1209)\u001b[0m \u001b[31mSELECT\u001b[0m\u001b[97m(-100, 4963)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m(date\u001b[0m\u001b[97m(-100, 12237)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m FROM\u001b[0m\u001b[97m(-100, 4393)\u001b[0m \u001b[31m table\u001b[0m\u001b[97m(-100, 2007)\u001b[0m \u001b[31m_name\u001b[0m\u001b[97m(-100, 1292)\u001b[0m \u001b[31m),\u001b[0m\u001b[97m(-100, 705)\u001b[0m \u001b[31m '-\u001b[0m\u001b[97m(-100, 7944)\u001b[0m \u001b[31m30\u001b[0m\u001b[97m(-100, 966)\u001b[0m \u001b[31m days\u001b[0m\u001b[97m(-100, 2919)\u001b[0m \u001b[31m')\n",
            "\u001b[0m\u001b[97m(-100, 1329)\u001b[0m \u001b[31m6\u001b[0m\u001b[97m(-100, 21)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m For\u001b[0m\u001b[97m(-100, 1789)\u001b[0m \u001b[31m rolling\u001b[0m\u001b[97m(-100, 20700)\u001b[0m \u001b[31m averages\u001b[0m\u001b[97m(-100, 49920)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m window\u001b[0m\u001b[97m(-100, 3321)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m sub\u001b[0m\u001b[97m(-100, 1207)\u001b[0m \u001b[31mqueries\u001b[0m\u001b[97m(-100, 43935)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m7\u001b[0m\u001b[97m(-100, 22)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m(app\u001b[0m\u001b[97m(-100, 11718)\u001b[0m \u001b[31mropriate\u001b[0m\u001b[97m(-100, 25264)\u001b[0m \u001b[31m_date\u001b[0m\u001b[97m(-100, 4257)\u001b[0m \u001b[31m_column\u001b[0m\u001b[97m(-100, 8918)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m find\u001b[0m\u001b[97m(-100, 1505)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m most\u001b[0m\u001b[97m(-100, 1455)\u001b[0m \u001b[31m recent\u001b[0m\u001b[97m(-100, 3293)\u001b[0m \u001b[31m date\u001b[0m\u001b[97m(-100, 2457)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m8\u001b[0m\u001b[97m(-100, 23)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m proper\u001b[0m\u001b[97m(-100, 6300)\u001b[0m \u001b[31m SQLite\u001b[0m\u001b[97m(-100, 29434)\u001b[0m \u001b[31m column\u001b[0m\u001b[97m(-100, 3330)\u001b[0m \u001b[31m types\u001b[0m\u001b[97m(-100, 4595)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m INTEGER\u001b[0m\u001b[97m(-100, 31481)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m TEXT\u001b[0m\u001b[97m(-100, 16139)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m REAL\u001b[0m\u001b[97m(-100, 26339)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m B\u001b[0m\u001b[97m(-100, 426)\u001b[0m \u001b[31mLOB\u001b[0m\u001b[97m(-100, 10911)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m9\u001b[0m\u001b[97m(-100, 24)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Handle\u001b[0m\u001b[97m(-100, 14078)\u001b[0m \u001b[31m foreign\u001b[0m\u001b[97m(-100, 7362)\u001b[0m \u001b[31m key\u001b[0m\u001b[97m(-100, 1401)\u001b[0m \u001b[31m relationships\u001b[0m\u001b[97m(-100, 12135)\u001b[0m \u001b[31m correctly\u001b[0m\u001b[97m(-100, 12722)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m proper\u001b[0m\u001b[97m(-100, 6300)\u001b[0m \u001b[31m JOIN\u001b[0m\u001b[97m(-100, 13369)\u001b[0m \u001b[31m syntax\u001b[0m\u001b[97m(-100, 20047)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mQUERY\u001b[0m\u001b[97m(-100, 42119)\u001b[0m \u001b[31m ST\u001b[0m\u001b[97m(-100, 4015)\u001b[0m \u001b[31mAND\u001b[0m\u001b[97m(-100, 4064)\u001b[0m \u001b[31mARDS\u001b[0m\u001b[97m(-100, 60994)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Write\u001b[0m\u001b[97m(-100, 9842)\u001b[0m \u001b[31m clear\u001b[0m\u001b[97m(-100, 2867)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m efficient\u001b[0m\u001b[97m(-100, 11297)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m appropriate\u001b[0m\u001b[97m(-100, 8475)\u001b[0m \u001b[31m aggregation\u001b[0m\u001b[97m(-100, 52729)\u001b[0m \u001b[31m functions\u001b[0m\u001b[97m(-100, 5865)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mCOUNT\u001b[0m\u001b[97m(-100, 39243)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m SUM\u001b[0m\u001b[97m(-100, 31835)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m AVG\u001b[0m\u001b[97m(-100, 71514)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m MAX\u001b[0m\u001b[97m(-100, 8498)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m MIN\u001b[0m\u001b[97m(-100, 17116)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Include\u001b[0m\u001b[97m(-100, 30834)\u001b[0m \u001b[31m proper\u001b[0m\u001b[97m(-100, 6300)\u001b[0m \u001b[31m GROUP\u001b[0m\u001b[97m(-100, 27968)\u001b[0m \u001b[31m BY\u001b[0m\u001b[97m(-100, 7866)\u001b[0m \u001b[31m and\u001b[0m\u001b[97m(-100, 323)\u001b[0m \u001b[31m ORDER\u001b[0m\u001b[97m(-100, 15888)\u001b[0m \u001b[31m BY\u001b[0m\u001b[97m(-100, 7866)\u001b[0m \u001b[31m clauses\u001b[0m\u001b[97m(-100, 50198)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m needed\u001b[0m\u001b[97m(-100, 4460)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m-\u001b[0m\u001b[97m(-100, 12)\u001b[0m \u001b[31m Use\u001b[0m\u001b[97m(-100, 5560)\u001b[0m \u001b[31m table\u001b[0m\u001b[97m(-100, 2007)\u001b[0m \u001b[31m aliases\u001b[0m\u001b[97m(-100, 41486)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m readability\u001b[0m\u001b[97m(-100, 92594)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m complex\u001b[0m\u001b[97m(-100, 6485)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mDatabase\u001b[0m\u001b[97m(-100, 6116)\u001b[0m \u001b[31m Schema\u001b[0m\u001b[97m(-100, 12824)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m accounts\u001b[0m\u001b[97m(-100, 9815)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m account\u001b[0m\u001b[97m(-100, 2759)\u001b[0m \u001b[31m_number\u001b[0m\u001b[97m(-100, 5617)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m balance\u001b[0m\u001b[97m(-100, 8335)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mDOUBLE\u001b[0m\u001b[97m(-100, 78747)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m account\u001b[0m\u001b[97m(-100, 2759)\u001b[0m \u001b[31m_type\u001b[0m\u001b[97m(-100, 1857)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m customers\u001b[0m\u001b[97m(-100, 6444)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m name\u001b[0m\u001b[97m(-100, 836)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m email\u001b[0m\u001b[97m(-100, 2613)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m phone\u001b[0m\u001b[97m(-100, 4641)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m loans\u001b[0m\u001b[97m(-100, 17017)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m loan\u001b[0m\u001b[97m(-100, 11941)\u001b[0m \u001b[31m_number\u001b[0m\u001b[97m(-100, 5617)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m amount\u001b[0m\u001b[97m(-100, 3392)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mDOUBLE\u001b[0m\u001b[97m(-100, 78747)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m interest\u001b[0m\u001b[97m(-100, 2802)\u001b[0m \u001b[31m_rate\u001b[0m\u001b[97m(-100, 9430)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mDOUBLE\u001b[0m\u001b[97m(-100, 78747)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m status\u001b[0m\u001b[97m(-100, 2704)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mTable\u001b[0m\u001b[97m(-100, 2620)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m transactions\u001b[0m\u001b[97m(-100, 14463)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m id\u001b[0m\u001b[97m(-100, 887)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m PRIMARY\u001b[0m\u001b[97m(-100, 38567)\u001b[0m \u001b[31m KEY\u001b[0m\u001b[97m(-100, 12282)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m transaction\u001b[0m\u001b[97m(-100, 7901)\u001b[0m \u001b[31m_type\u001b[0m\u001b[97m(-100, 1857)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mVARCHAR\u001b[0m\u001b[97m(-100, 80751)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m amount\u001b[0m\u001b[97m(-100, 3392)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mDOUBLE\u001b[0m\u001b[97m(-100, 78747)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m timestamp\u001b[0m\u001b[97m(-100, 11695)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mTIM\u001b[0m\u001b[97m(-100, 35248)\u001b[0m \u001b[31mESTAMP\u001b[0m\u001b[97m(-100, 31755)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\u001b[0m\u001b[97m(-100, 340)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m -\u001b[0m\u001b[97m(-100, 482)\u001b[0m \u001b[31m account\u001b[0m\u001b[97m(-100, 2759)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mBIG\u001b[0m\u001b[97m(-100, 68117)\u001b[0m \u001b[31mINT\u001b[0m\u001b[97m(-100, 3301)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m NULL\u001b[0m\u001b[97m(-100, 1808)\u001b[0m \u001b[31m)\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 696)\u001b[0m \u001b[31mQuestion\u001b[0m\u001b[97m(-100, 14924)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m Which\u001b[0m\u001b[97m(-100, 16299)\u001b[0m \u001b[31m account\u001b[0m\u001b[97m(-100, 2759)\u001b[0m \u001b[31m type\u001b[0m\u001b[97m(-100, 955)\u001b[0m \u001b[31m has\u001b[0m\u001b[97m(-100, 706)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m highest\u001b[0m\u001b[97m(-100, 8592)\u001b[0m \u001b[31m average\u001b[0m\u001b[97m(-100, 5578)\u001b[0m \u001b[31m balance\u001b[0m\u001b[97m(-100, 8335)\u001b[0m \u001b[31m?\u001b[0m\u001b[97m(-100, 30)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[32mSELECT\u001b[0m\u001b[97m(4963, 4963)\u001b[0m \u001b[32m account\u001b[0m\u001b[97m(2759, 2759)\u001b[0m \u001b[32m_type\u001b[0m\u001b[97m(1857, 1857)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m AVG\u001b[0m\u001b[97m(71514, 71514)\u001b[0m \u001b[32m(balance\u001b[0m\u001b[97m(91721, 91721)\u001b[0m \u001b[32m)\u001b[0m\u001b[97m(8, 8)\u001b[0m \u001b[32m AS\u001b[0m\u001b[97m(5871, 5871)\u001b[0m \u001b[32m avg\u001b[0m\u001b[97m(20291, 20291)\u001b[0m \u001b[32m_balance\u001b[0m\u001b[97m(30496, 30496)\u001b[0m \u001b[32m FROM\u001b[0m\u001b[97m(4393, 4393)\u001b[0m \u001b[32m accounts\u001b[0m\u001b[97m(9815, 9815)\u001b[0m \u001b[32m GROUP\u001b[0m\u001b[97m(27968, 27968)\u001b[0m \u001b[32m BY\u001b[0m\u001b[97m(7866, 7866)\u001b[0m \u001b[32m account\u001b[0m\u001b[97m(2759, 2759)\u001b[0m \u001b[32m_type\u001b[0m\u001b[97m(1857, 1857)\u001b[0m \u001b[32m ORDER\u001b[0m\u001b[97m(15888, 15888)\u001b[0m \u001b[32m BY\u001b[0m\u001b[97m(7866, 7866)\u001b[0m \u001b[32m avg\u001b[0m\u001b[97m(20291, 20291)\u001b[0m \u001b[32m_balance\u001b[0m\u001b[97m(30496, 30496)\u001b[0m \u001b[32m DESC\u001b[0m\u001b[97m(16477, 16477)\u001b[0m \u001b[32m LIMIT\u001b[0m\u001b[97m(10592, 10592)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m;\u001b[0m\u001b[97m(26, 26)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m\u001b[39m\n",
            "[2025-06-26 03:42:18,477] [INFO] [axolotl.utils.tokenization.check_example_labels:45] [PID:3849] [RANK:0] \n",
            "\n",
            "\n",
            "\u001b[39m\n",
            "[2025-06-26 03:42:18,477] [INFO] [axolotl.utils.tokenization.check_example_labels:48] [PID:3849] [RANK:0] Total input len: 515\u001b[39m\n",
            "[2025-06-26 03:42:18,477] [INFO] [axolotl.utils.tokenization.check_example_labels:49] [PID:3849] [RANK:0] Count of labels: 26\u001b[39m\n",
            "[2025-06-26 03:42:18,477] [INFO] [axolotl.common.datasets.load_datasets:86] [PID:3849] [RANK:0] printing prompters...\u001b[39m\n",
            "[2025-06-26 03:42:18,477] [INFO] [axolotl.common.datasets.load_datasets:88] [PID:3849] [RANK:0] Pre-tokenized or custom dataset types are unsupported for logging\u001b[39m\n",
            "We detected that you are using `from_pretrained` with a meta device context manager or `torch.set_default_device('meta')`\n",
            "This is an anti-pattern and will raise an Error in version v4.53\n",
            "If you want to initialize a model on the meta device, use the context manager or global device with `from_config`, or `ModelClass(config)`\n",
            "model.safetensors: 100% 2.47G/2.47G [00:12<00:00, 202MB/s]\n",
            "generation_config.json: 100% 186/186 [00:00<00:00, 1.08MB/s]\n",
            "[2025-06-26 03:42:32,686] [INFO] [axolotl.cli.preprocess.do_preprocess:75] [PID:3849] [RANK:0] \u001b[32mSuccess! Preprocessed data path: `dataset_prepared_path: last_run_prepared`\u001b[39m\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Prepare the datasets\n",
        "!axolotl preprocess axolotl.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzfM3wD9T2Kl"
      },
      "source": [
        "## Step 6: Start Training\n",
        "\n",
        "This will begin the fine-tuning process. Expected behavior:\n",
        "\n",
        "**Training Progress**:\n",
        "- 10 epochs of training (may take 30-60 minutes on L4 GPU)\n",
        "- Loss should decrease over time\n",
        "- Validation evaluations every ~25% of each epoch\n",
        "\n",
        "**What to Watch For**:\n",
        "- **Training loss decreasing**: Model is learning\n",
        "- **Validation loss stable/decreasing**: Not overfitting\n",
        "- **GPU memory usage**: Should be stable throughout training\n",
        "\n",
        "**Troubleshooting**:\n",
        "- If OOM (Out of Memory): Reduce `micro_batch_size` to 1\n",
        "- If loss not decreasing: Check data format and increase learning rate\n",
        "- If overfitting: Reduce `num_epochs` or increase regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWb-L0YfvIW9",
        "outputId": "242f5d54-35e8-480c-fdd6-4a0bef223a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-26 03:43:25.433874: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-26 03:43:25.450655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909405.471594    5929 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909405.478031    5929 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-26 03:43:25.498684: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-06-26 03:43:41.410076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909421.430590    6058 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909421.436846    6058 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[2025-06-26 03:43:45,840] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:6058] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
            "[2025-06-26 03:43:46,189] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:6058] [RANK:0] cuda memory usage baseline: 0.000GB (+0.336GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "[2025-06-26 03:43:47,878] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:461] [PID:6058] [RANK:0] Loading prepared dataset from disk at last_run_prepared/7ba8589d17aa28a57c086c50105c21e8...\u001b[39m\n",
            "[2025-06-26 03:43:47,883] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:461] [PID:6058] [RANK:0] Loading prepared dataset from disk at last_run_prepared/ef8e57ca0db555d5afeed025b7bdb888...\u001b[39m\n",
            "2025-06-26 03:43:53.046718: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909433.067904    6133 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909433.074380    6133 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:44:05.320560: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909445.341276    6194 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909445.347623    6194 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:44:17.471398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909457.492298    6251 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909457.498686    6251 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:44:29.691969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909469.712679    6308 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909469.719001    6308 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:44:42.030068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909482.050901    6371 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909482.057251    6371 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:44:54.403214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909494.425295    6428 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909494.431938    6428 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:45:06.704773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909506.725604    6489 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909506.731914    6489 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:45:18.982856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909519.004364    6550 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909519.010670    6550 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:45:31.247049: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909531.268398    6607 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909531.274849    6607 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m[2025-06-26 03:45:38,297] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:6058] [RANK:0] gather_len_batches: [20]\u001b[39m\n",
            "[2025-06-26 03:45:38,298] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:6058] [RANK:0] Maximum number of steps set at 50\u001b[39m\n",
            "[2025-06-26 03:45:45,952] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:6058] [RANK:0] cuda memory usage after model load: 1.408GB (+0.090GB cache, +0.520GB misc)\u001b[39m\n",
            "[2025-06-26 03:45:45,987] [INFO] [axolotl.loaders.model._prepare_model_for_quantization:762] [PID:6058] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2025-06-26 03:45:45,988] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:6058] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
            "[2025-06-26 03:45:45,990] [INFO] [axolotl.loaders.adapter.load_lora:82] [PID:6058] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "trainable params: 22,544,384 || all params: 1,258,358,784 || trainable%: 1.7916\n",
            "[2025-06-26 03:45:46,359] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:6058] [RANK:0] cuda memory usage after adapters: 1.492GB (+1.086GB cache, +0.547GB misc)\u001b[39m\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "[2025-06-26 03:45:52,921] [INFO] [axolotl.train.save_initial_configs:403] [PID:6058] [RANK:0] Pre-saving adapter config to ./outputs/lora-out...\u001b[39m\n",
            "[2025-06-26 03:45:52,922] [INFO] [axolotl.train.save_initial_configs:407] [PID:6058] [RANK:0] Pre-saving tokenizer to ./outputs/lora-out...\u001b[39m\n",
            "[2025-06-26 03:45:53,142] [INFO] [axolotl.train.save_initial_configs:410] [PID:6058] [RANK:0] Pre-saving model config to ./outputs/lora-out...\u001b[39m\n",
            "[2025-06-26 03:45:53,145] [INFO] [axolotl.train.execute_training:225] [PID:6058] [RANK:0] Starting trainer...\u001b[39m\n",
            "2025-06-26 03:45:58.846236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909558.867534    6764 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909558.874076    6764 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:46:11.220669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909571.241348    6855 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909571.247714    6855 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:46:23.528126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909583.548775    6912 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909583.555053    6912 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:46:35.844555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909595.864966    6969 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909595.871181    6969 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:46:48.073676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909608.095183    7026 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909608.101589    7026 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:47:00.380391: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909620.401382    7085 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909620.407825    7085 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:47:12.665404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909632.686358    7142 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909632.692703    7142 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:47:24.957383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909644.978345    7199 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909644.984602    7199 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:47:37.297059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909657.317506    7260 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909657.323729    7260 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m[2025-06-26 03:47:44,486] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:6058] [RANK:0] gather_len_batches: [19]\u001b[39m\n",
            "  0% 0/50 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.82it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  3.10it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.61it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:00,  2.14it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.13it/s]\u001b[A\n",
            "                          \n",
            "\u001b[A{'eval_loss': 0.8705242872238159, 'eval_runtime': 4.4335, 'eval_samples_per_second': 3.383, 'eval_steps_per_second': 1.804, 'epoch': 0}\n",
            "  0% 0/50 [00:04<?, ?it/s]\n",
            "100% 7/7 [00:03<00:00,  2.11it/s]\u001b[A\n",
            "                                 \u001b[A2025-06-26 03:47:54.209489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909674.230588    7338 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909674.237008    7338 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:48:06.640068: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909686.660993    7401 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909686.667385    7401 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "{'loss': 1.0151, 'grad_norm': 0.9340329170227051, 'learning_rate': 0.0, 'epoch': 0.21}\n",
            "  2% 1/50 [00:35<28:43, 35.18s/it][2025-06-26 03:48:25,543] [INFO] [axolotl.utils.callbacks.log_gpu_memory_usage:107] [PID:6058] [RANK:0] cuda memory usage while training: 1.555GB (+7.527GB cache, +0.581GB misc)\u001b[39m\n",
            "{'loss': 0.9457, 'grad_norm': 0.8440359234809875, 'learning_rate': 2e-05, 'epoch': 0.42}\n",
            "  4% 2/50 [00:40<14:19, 17.91s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.13it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.51it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:00,  2.00it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.04it/s]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.8693450093269348, 'eval_runtime': 3.6007, 'eval_samples_per_second': 4.166, 'eval_steps_per_second': 2.222, 'epoch': 0.42}\n",
            "  4% 2/50 [00:44<14:19, 17.91s/it]\n",
            "100% 7/7 [00:03<00:00,  2.05it/s]\u001b[A\n",
            "{'loss': 0.9606, 'grad_norm': 0.7999804019927979, 'learning_rate': 4e-05, 'epoch': 0.63}\n",
            "{'loss': 0.9646, 'grad_norm': 0.8572558760643005, 'learning_rate': 6e-05, 'epoch': 0.84}\n",
            "  8% 4/50 [00:56<08:17, 10.82s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.12it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.51it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  2.00it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.03it/s]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.8455540537834167, 'eval_runtime': 3.617, 'eval_samples_per_second': 4.147, 'eval_steps_per_second': 2.212, 'epoch': 0.84}\n",
            "  8% 4/50 [00:59<08:17, 10.82s/it]\n",
            "100% 7/7 [00:03<00:00,  2.04it/s]\u001b[A\n",
            "{'loss': 0.914, 'grad_norm': 0.8120985627174377, 'learning_rate': 8e-05, 'epoch': 1.0}\n",
            " 10% 5/50 [01:04<07:21,  9.82s/it]2025-06-26 03:48:55.169561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909735.190464    7613 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909735.196962    7613 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:49:07.459742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909747.480811    7670 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909747.487294    7670 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.9037, 'grad_norm': 0.8075337409973145, 'learning_rate': 0.0001, 'epoch': 1.21}\n",
            " 12% 6/50 [01:35<12:36, 17.18s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.09it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.71046382188797, 'eval_runtime': 3.6355, 'eval_samples_per_second': 4.126, 'eval_steps_per_second': 2.201, 'epoch': 1.21}\n",
            " 12% 6/50 [01:39<12:36, 17.18s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.792, 'grad_norm': 0.6305413842201233, 'learning_rate': 0.00012, 'epoch': 1.42}\n",
            "{'loss': 0.6906, 'grad_norm': 0.5706942081451416, 'learning_rate': 0.00014, 'epoch': 1.63}\n",
            " 16% 8/50 [01:51<08:19, 11.90s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.10it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.50it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.03it/s]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.5845640301704407, 'eval_runtime': 3.629, 'eval_samples_per_second': 4.133, 'eval_steps_per_second': 2.204, 'epoch': 1.63}\n",
            " 16% 8/50 [01:54<08:19, 11.90s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.6178, 'grad_norm': 0.6630332469940186, 'learning_rate': 0.00016, 'epoch': 1.84}\n",
            "{'loss': 0.555, 'grad_norm': 0.4991249740123749, 'learning_rate': 0.00018, 'epoch': 2.0}\n",
            " 20% 10/50 [02:05<06:03,  9.10s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.86it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.511559009552002, 'eval_runtime': 3.6443, 'eval_samples_per_second': 4.116, 'eval_steps_per_second': 2.195, 'epoch': 2.0}\n",
            " 20% 10/50 [02:08<06:03,  9.10s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "                                 \u001b[A2025-06-26 03:49:59.907608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909799.929500    7891 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909799.936344    7891 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:50:12.530857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909812.551841    7952 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909812.558155    7952 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.5244, 'grad_norm': 0.49507972598075867, 'learning_rate': 0.0002, 'epoch': 2.21}\n",
            "{'loss': 0.5498, 'grad_norm': 0.7200641632080078, 'learning_rate': 0.0001996917333733128, 'epoch': 2.42}\n",
            " 24% 12/50 [02:47<08:44, 13.81s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.10it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.48978322744369507, 'eval_runtime': 3.6448, 'eval_samples_per_second': 4.115, 'eval_steps_per_second': 2.195, 'epoch': 2.42}\n",
            " 24% 12/50 [02:50<08:44, 13.81s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.4722, 'grad_norm': 0.6908479928970337, 'learning_rate': 0.00019876883405951377, 'epoch': 2.63}\n",
            "{'loss': 0.5114, 'grad_norm': 0.7116842269897461, 'learning_rate': 0.00019723699203976766, 'epoch': 2.84}\n",
            " 28% 14/50 [03:02<06:19, 10.55s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.46983495354652405, 'eval_runtime': 3.6398, 'eval_samples_per_second': 4.121, 'eval_steps_per_second': 2.198, 'epoch': 2.84}\n",
            " 28% 14/50 [03:06<06:19, 10.55s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.4074, 'grad_norm': 0.6816814541816711, 'learning_rate': 0.00019510565162951537, 'epoch': 3.0}\n",
            " 30% 15/50 [03:10<05:43,  9.81s/it]2025-06-26 03:51:01.572538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909861.593839    8161 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909861.600417    8161 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:51:14.014809: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909874.035858    8218 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909874.042258    8218 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.387, 'grad_norm': 0.4460482895374298, 'learning_rate': 0.0001923879532511287, 'epoch': 3.21}\n",
            " 32% 16/50 [03:42<09:18, 16.44s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.08it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.44355982542037964, 'eval_runtime': 3.6358, 'eval_samples_per_second': 4.126, 'eval_steps_per_second': 2.2, 'epoch': 3.21}\n",
            " 32% 16/50 [03:46<09:18, 16.44s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.422, 'grad_norm': 0.5721762180328369, 'learning_rate': 0.0001891006524188368, 'epoch': 3.42}\n",
            "{'loss': 0.3512, 'grad_norm': 0.3995629549026489, 'learning_rate': 0.00018526401643540922, 'epoch': 3.63}\n",
            " 36% 18/50 [03:58<06:18, 11.84s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.4033381938934326, 'eval_runtime': 3.6506, 'eval_samples_per_second': 4.109, 'eval_steps_per_second': 2.191, 'epoch': 3.63}\n",
            " 36% 18/50 [04:01<06:18, 11.84s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.4358, 'grad_norm': 0.47228896617889404, 'learning_rate': 0.00018090169943749476, 'epoch': 3.84}\n",
            "{'loss': 0.3278, 'grad_norm': 0.4100799560546875, 'learning_rate': 0.0001760405965600031, 'epoch': 4.0}\n",
            " 40% 20/50 [04:12<04:34,  9.15s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.08it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.86it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3903753161430359, 'eval_runtime': 3.6461, 'eval_samples_per_second': 4.114, 'eval_steps_per_second': 2.194, 'epoch': 4.0}\n",
            " 40% 20/50 [04:15<04:34,  9.15s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "                                 \u001b[A2025-06-26 03:52:06.748516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909926.769821    8451 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909926.776235    8451 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:52:19.199835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909939.221178    8510 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909939.227688    8510 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.3575, 'grad_norm': 0.4426344335079193, 'learning_rate': 0.00017071067811865476, 'epoch': 4.21}\n",
            "{'loss': 0.3375, 'grad_norm': 0.38187307119369507, 'learning_rate': 0.00016494480483301836, 'epoch': 4.42}\n",
            " 44% 22/50 [04:53<06:24, 13.73s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.06it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.382077693939209, 'eval_runtime': 3.6378, 'eval_samples_per_second': 4.123, 'eval_steps_per_second': 2.199, 'epoch': 4.42}\n",
            " 44% 22/50 [04:57<06:24, 13.73s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.3147, 'grad_norm': 0.4111863076686859, 'learning_rate': 0.00015877852522924732, 'epoch': 4.63}\n",
            "{'loss': 0.3273, 'grad_norm': 0.32484179735183716, 'learning_rate': 0.0001522498564715949, 'epoch': 4.84}\n",
            " 48% 24/50 [05:09<04:33, 10.52s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.38200971484184265, 'eval_runtime': 3.649, 'eval_samples_per_second': 4.111, 'eval_steps_per_second': 2.192, 'epoch': 4.84}\n",
            " 48% 24/50 [05:12<04:33, 10.52s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.3121, 'grad_norm': 0.4507220387458801, 'learning_rate': 0.00014539904997395468, 'epoch': 5.0}\n",
            " 50% 25/50 [05:17<04:05,  9.80s/it]2025-06-26 03:53:08.093924: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750909988.116496    8719 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750909988.123321    8719 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:53:20.522862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910000.543716    8776 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910000.550018    8776 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.2941, 'grad_norm': 0.2585967779159546, 'learning_rate': 0.000138268343236509, 'epoch': 5.21}\n",
            " 52% 26/50 [05:49<06:33, 16.41s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.08it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3775205612182617, 'eval_runtime': 3.6351, 'eval_samples_per_second': 4.126, 'eval_steps_per_second': 2.201, 'epoch': 5.21}\n",
            " 52% 26/50 [05:52<06:33, 16.41s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.3463, 'grad_norm': 0.30851835012435913, 'learning_rate': 0.00013090169943749476, 'epoch': 5.42}\n",
            "{'loss': 0.2586, 'grad_norm': 0.3279312252998352, 'learning_rate': 0.00012334453638559057, 'epoch': 5.63}\n",
            " 56% 28/50 [06:04<04:20, 11.84s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.04it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3659607470035553, 'eval_runtime': 3.6494, 'eval_samples_per_second': 4.11, 'eval_steps_per_second': 2.192, 'epoch': 5.63}\n",
            " 56% 28/50 [06:08<04:20, 11.84s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.2776, 'grad_norm': 0.26178112626075745, 'learning_rate': 0.0001156434465040231, 'epoch': 5.84}\n",
            "{'loss': 0.2621, 'grad_norm': 0.3577142655849457, 'learning_rate': 0.0001078459095727845, 'epoch': 6.0}\n",
            " 60% 30/50 [06:18<03:02,  9.15s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.10it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.37078434228897095, 'eval_runtime': 3.6376, 'eval_samples_per_second': 4.124, 'eval_steps_per_second': 2.199, 'epoch': 6.0}\n",
            " 60% 30/50 [06:22<03:02,  9.15s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "                                 \u001b[A2025-06-26 03:54:13.217200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910053.238720    9007 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910053.245168    9007 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:54:25.517696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910065.538909    9062 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910065.545382    9062 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.2499, 'grad_norm': 0.2077072709798813, 'learning_rate': 0.0001, 'epoch': 6.21}\n",
            "{'loss': 0.2921, 'grad_norm': 0.278259813785553, 'learning_rate': 9.215409042721552e-05, 'epoch': 6.42}\n",
            " 64% 32/50 [06:59<04:05, 13.66s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.10it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3660402297973633, 'eval_runtime': 3.6332, 'eval_samples_per_second': 4.129, 'eval_steps_per_second': 2.202, 'epoch': 6.42}\n",
            " 64% 32/50 [07:03<04:05, 13.66s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.2508, 'grad_norm': 0.2509499192237854, 'learning_rate': 8.435655349597689e-05, 'epoch': 6.63}\n",
            "{'loss': 0.2313, 'grad_norm': 0.24776031076908112, 'learning_rate': 7.66554636144095e-05, 'epoch': 6.84}\n",
            " 68% 34/50 [07:15<02:47, 10.49s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.06it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.35429075360298157, 'eval_runtime': 3.6487, 'eval_samples_per_second': 4.111, 'eval_steps_per_second': 2.193, 'epoch': 6.84}\n",
            " 68% 34/50 [07:18<02:47, 10.49s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.291, 'grad_norm': 0.3068036139011383, 'learning_rate': 6.909830056250527e-05, 'epoch': 7.0}\n",
            " 70% 35/50 [07:23<02:26,  9.78s/it]2025-06-26 03:55:14.305758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910114.326734    9269 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910114.333101    9269 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:55:26.583277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910126.604144    9324 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910126.610507    9324 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.2353, 'grad_norm': 0.2195340245962143, 'learning_rate': 6.173165676349103e-05, 'epoch': 7.21}\n",
            " 72% 36/50 [07:54<03:48, 16.30s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3533725440502167, 'eval_runtime': 3.6373, 'eval_samples_per_second': 4.124, 'eval_steps_per_second': 2.199, 'epoch': 7.21}\n",
            " 72% 36/50 [07:58<03:48, 16.30s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.2469, 'grad_norm': 0.23237523436546326, 'learning_rate': 5.4600950026045326e-05, 'epoch': 7.42}\n",
            "{'loss': 0.2491, 'grad_norm': 0.2595612406730652, 'learning_rate': 4.7750143528405126e-05, 'epoch': 7.63}\n",
            " 76% 38/50 [08:10<02:21, 11.78s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.86it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.01it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.35594063997268677, 'eval_runtime': 3.6522, 'eval_samples_per_second': 4.107, 'eval_steps_per_second': 2.19, 'epoch': 7.63}\n",
            " 76% 38/50 [08:14<02:21, 11.78s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.2581, 'grad_norm': 0.2583453357219696, 'learning_rate': 4.12214747707527e-05, 'epoch': 7.84}\n",
            "{'loss': 0.2237, 'grad_norm': 0.22957174479961395, 'learning_rate': 3.5055195166981645e-05, 'epoch': 8.0}\n",
            " 80% 40/50 [08:24<01:31,  9.13s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.06it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.47it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.97it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.01it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.36750125885009766, 'eval_runtime': 3.6617, 'eval_samples_per_second': 4.096, 'eval_steps_per_second': 2.185, 'epoch': 8.0}\n",
            " 80% 40/50 [08:28<01:31,  9.13s/it]\n",
            "100% 7/7 [00:03<00:00,  2.01it/s]\u001b[A\n",
            "                                 \u001b[A2025-06-26 03:56:19.141696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910179.162802    9543 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910179.169243    9543 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:56:31.724445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910191.745337    9606 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910191.751678    9606 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.2189, 'grad_norm': 0.20147639513015747, 'learning_rate': 2.9289321881345254e-05, 'epoch': 8.21}\n",
            "{'loss': 0.2242, 'grad_norm': 0.24483241140842438, 'learning_rate': 2.3959403439996907e-05, 'epoch': 8.42}\n",
            " 84% 42/50 [09:06<01:49, 13.75s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.11it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.50it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.36585181951522827, 'eval_runtime': 3.6377, 'eval_samples_per_second': 4.123, 'eval_steps_per_second': 2.199, 'epoch': 8.42}\n",
            " 84% 42/50 [09:09<01:49, 13.75s/it]\n",
            "100% 7/7 [00:03<00:00,  2.03it/s]\u001b[A\n",
            "{'loss': 0.2241, 'grad_norm': 0.23698371648788452, 'learning_rate': 1.9098300562505266e-05, 'epoch': 8.63}\n",
            "{'loss': 0.267, 'grad_norm': 0.21434687077999115, 'learning_rate': 1.4735983564590783e-05, 'epoch': 8.84}\n",
            " 88% 44/50 [09:21<01:03, 10.53s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.04it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.01it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.36064866185188293, 'eval_runtime': 3.654, 'eval_samples_per_second': 4.105, 'eval_steps_per_second': 2.189, 'epoch': 8.84}\n",
            " 88% 44/50 [09:25<01:03, 10.53s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.2504, 'grad_norm': 0.3215586841106415, 'learning_rate': 1.0899347581163221e-05, 'epoch': 9.0}\n",
            " 90% 45/50 [09:29<00:49,  9.81s/it]2025-06-26 03:57:20.670703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910240.692171    9821 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910240.698718    9821 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m2025-06-26 03:57:33.019681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750910253.041213    9880 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750910253.047797    9880 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 0.2268, 'grad_norm': 0.22476422786712646, 'learning_rate': 7.612046748871327e-06, 'epoch': 9.21}\n",
            " 92% 46/50 [10:01<01:05, 16.36s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.08it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.49it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.99it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.03it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.37445688247680664, 'eval_runtime': 3.6204, 'eval_samples_per_second': 4.143, 'eval_steps_per_second': 2.21, 'epoch': 9.21}\n",
            " 92% 46/50 [10:05<01:05, 16.36s/it]\n",
            "100% 7/7 [00:03<00:00,  2.04it/s]\u001b[A\n",
            "{'loss': 0.2401, 'grad_norm': 0.2232300341129303, 'learning_rate': 4.8943483704846475e-06, 'epoch': 9.42}\n",
            "{'loss': 0.2382, 'grad_norm': 0.2632470726966858, 'learning_rate': 2.7630079602323442e-06, 'epoch': 9.63}\n",
            " 96% 48/50 [10:16<00:23, 11.80s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.86it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.48it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.98it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.02it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.36692681908607483, 'eval_runtime': 3.6465, 'eval_samples_per_second': 4.114, 'eval_steps_per_second': 2.194, 'epoch': 9.63}\n",
            " 96% 48/50 [10:20<00:23, 11.80s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'loss': 0.2387, 'grad_norm': 0.18377307057380676, 'learning_rate': 1.231165940486234e-06, 'epoch': 9.84}\n",
            "{'loss': 0.2204, 'grad_norm': 0.2120421826839447, 'learning_rate': 3.0826662668720364e-07, 'epoch': 10.0}\n",
            "100% 50/50 [10:30<00:00,  9.14s/it]\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:01,  4.06it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:01,  2.85it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:01,  2.47it/s]\u001b[A\n",
            " 71% 5/7 [00:02<00:01,  1.97it/s]\u001b[A\n",
            " 86% 6/7 [00:02<00:00,  2.01it/s]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.3570801913738251, 'eval_runtime': 3.6581, 'eval_samples_per_second': 4.1, 'eval_steps_per_second': 2.187, 'epoch': 10.0}\n",
            "100% 50/50 [10:34<00:00,  9.14s/it]\n",
            "100% 7/7 [00:03<00:00,  2.02it/s]\u001b[A\n",
            "{'train_runtime': 635.7898, 'train_samples_per_second': 0.629, 'train_steps_per_second': 0.079, 'train_loss': 0.4142554071545601, 'epoch': 10.0}\n",
            "100% 50/50 [10:35<00:00, 12.72s/it]\n",
            "[2025-06-26 03:58:20,365] [INFO] [axolotl.train.save_trained_model:244] [PID:6058] [RANK:0] Training completed! Saving trained model to ./outputs/lora-out.\u001b[39m\n",
            "[2025-06-26 03:58:21,093] [INFO] [axolotl.train.save_trained_model:341] [PID:6058] [RANK:0] Model successfully saved to ./outputs/lora-out\u001b[39m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "!axolotl train axolotl.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6612OY1T2Kl"
      },
      "source": [
        "## Step 7: Optional - Merge LoRA Weights\n",
        "\n",
        "**What this does**: Combines the base model with LoRA adapter into a single model file\n",
        "\n",
        "**When to use**:\n",
        "- ✅ **For inference/deployment**: Single file is easier to use\n",
        "- ✅ **For sharing**: Recipients don't need both base model + adapter\n",
        "- ❌ **For further training**: Keep adapter separate for additional fine-tuning\n",
        "- ❌ **With multiple adapters**: If you have multiple adapters you want to serve from the same base model, it's better to keep them separate.\n",
        "\n",
        "**Trade-offs**:\n",
        "- **Pros**: Simpler deployment, no adapter loading required\n",
        "- **Cons**: Larger file size, can't easily swap adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHS51j2TT2Kl"
      },
      "outputs": [],
      "source": [
        "# !python -m axolotl.cli.merge_lora axolotl.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2-Gx3SuT2Kl"
      },
      "source": [
        "## Step 8: Upload to HuggingFace Hub\n",
        "\n",
        "**Sharing your model**:\n",
        "- Makes your fine-tuned model publicly available\n",
        "- Others can use it with `transformers` library or other inference libraries like vLLM.\n",
        "- Enables easy deployment and inference\n",
        "\n",
        "**What gets uploaded**:\n",
        "- LoRA adapter weights (`adapter_model.bin`)\n",
        "- Configuration files (`adapter_config.json`)\n",
        "- Training metadata and logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sfmtXqLzvc_",
        "outputId": "f2195f62-0ac8-4e54-e16f-ffe9c890baa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start hashing 8 files.\n",
            "Finished hashing 8 files.\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "adapter_model.safetensors:   0% 0.00/90.2M [00:00<?, ?B/s]\u001b[A\n",
            "adapter_model.safetensors:  18% 16.0M/90.2M [00:00<00:03, 21.0MB/s]\u001b[A\n",
            "adapter_model.safetensors:  53% 48.0M/90.2M [00:01<00:01, 27.3MB/s]\u001b[A\n",
            "adapter_model.safetensors:  71% 64.0M/90.2M [00:02<00:00, 34.2MB/s]\u001b[A\n",
            "adapter_model.safetensors: 96.0MB [00:03, 28.4MB/s]\n",
            "100% 1/1 [00:03<00:00,  3.76s/it]\n",
            "Removing 5 file(s) from commit that have not changed.\n",
            "https://huggingface.co/mgfrantz/NousResearch-Llama-3.2-1B-ctme-sql-demo/tree/main/.\n"
          ]
        }
      ],
      "source": [
        "# [optional] upload to hf hub\n",
        "import os\n",
        "\n",
        "username = \"mgfrantz\"\n",
        "repo_name = \"NousResearch-Llama-3.2-1B-ctme-sql-demo\"\n",
        "if not username:\n",
        "    username = input(\"Username: \")\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "!rm -r outputs/lora-out/checkpoint-* # we only want to push the final checkpoint since we loaded the best one back at the end\n",
        "!huggingface-cli upload {username}/{repo_name} ./outputs/lora-out/ ."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0b5skwkYy4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}