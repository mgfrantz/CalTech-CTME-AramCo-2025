{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../output/validated_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "duckdb.execute(\"\"\"\n",
    "INSTALL sqlite;\n",
    "LOAD sqlite;               \n",
    "\"\"\")\n",
    "\n",
    "def query_sqlite(query:str, db_path:str) -> pd.DataFrame:\n",
    "    conn = duckdb.connect(db_path)\n",
    "    return conn.execute(query).fetch_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = df.db_path.iloc[0]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = query_sqlite('SHOW TABLES', path)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables.name:\n",
    "    print(table)\n",
    "    display(t:=query_sqlite(f'DESCRIBE TABLE {table}', path).dropna(how='all', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_metadata(db_path:str) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get metadata for all tables in the database.\n",
    "    \"\"\"\n",
    "    tables = query_sqlite('SHOW TABLES', db_path)\n",
    "    metadata = {}\n",
    "    for table in tables.name:\n",
    "        metadata[table] = query_sqlite(f'DESCRIBE TABLE {table}', db_path).dropna(how='all', axis=1)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_schema_for_chat(metadata: dict[str, pd.DataFrame]) -> str:\n",
    "    \"\"\"\n",
    "    Format table metadata into a readable string for chat training.\n",
    "    \"\"\"\n",
    "    schema_lines = []\n",
    "    \n",
    "    for table_name, df in metadata.items():\n",
    "        schema_lines.append(f\"Table: {table_name}\")\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            col_info = f\"  - {row['column_name']} ({row['column_type']}\"\n",
    "            if row['key'] == 'PRI':\n",
    "                col_info += \", PRIMARY KEY\"\n",
    "            elif pd.notna(row['key']) and row['key'] != 'None':\n",
    "                col_info += f\", {row['key']}\"\n",
    "            if row['null'] == 'NO':\n",
    "                col_info += \", NOT NULL\"\n",
    "            col_info += \")\"\n",
    "            schema_lines.append(col_info)\n",
    "        \n",
    "        schema_lines.append(\"\")  # Add blank line between tables\n",
    "    \n",
    "    return \"\\n\".join(schema_lines).strip()\n",
    "\n",
    "def create_chatml_dataset(df: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Create ChatML conversations format dataset directly from DataFrame.\n",
    "    Includes system prompt with SQLite constraints.\n",
    "    \"\"\"\n",
    "    # SQLite-focused system prompt based on constraints from prompts.py\n",
    "    system_prompt = \"\"\"You are an expert SQL developer specializing in SQLite. Generate accurate SQL queries that follow these requirements:\n",
    "\n",
    "SQLITE REQUIREMENTS:\n",
    "1. Use only standard SQLite-compatible SQL syntax\n",
    "2. Avoid PostgreSQL-specific functions like INTERVAL - use date arithmetic instead\n",
    "3. Use SQLite date functions: date(), datetime(), julianday() for date calculations\n",
    "4. For \"recent month\" use: WHERE date_column >= date((SELECT MAX(date_column) FROM table_name), '-1 month')\n",
    "5. For \"past 30 days\" use: WHERE date_column >= date((SELECT MAX(date_column) FROM table_name), '-30 days')\n",
    "6. For rolling averages, use window functions or subqueries\n",
    "7. Use MAX(appropriate_date_column) to find the most recent date\n",
    "8. Use proper SQLite column types: INTEGER, TEXT, REAL, BLOB\n",
    "9. Handle foreign key relationships correctly with proper JOIN syntax\n",
    "\n",
    "QUERY STANDARDS:\n",
    "- Write clear, efficient queries\n",
    "- Use appropriate aggregation functions (COUNT, SUM, AVG, MAX, MIN)\n",
    "- Include proper GROUP BY and ORDER BY clauses when needed\n",
    "- Use table aliases for readability in complex queries\"\"\"\n",
    "\n",
    "    chatml_data = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating ChatML dataset\"):\n",
    "        # Skip invalid entries\n",
    "        if not row['is_valid']:\n",
    "            continue\n",
    "            \n",
    "        # Get table metadata for this database\n",
    "        metadata = table_metadata(row['db_path'])\n",
    "        schema_text = format_schema_for_chat(metadata)\n",
    "        \n",
    "        # Create user message with schema and question\n",
    "        user_content = f\"Database Schema:\\n{schema_text}\\n\\nQuestion: {row['question']}\"\n",
    "        \n",
    "        # Create ChatML conversation with system prompt\n",
    "        chatml_entry = {\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_content\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": row['query']\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        chatml_data.append(chatml_entry)\n",
    "    \n",
    "    return chatml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ChatML format dataset for Axolotl\n",
    "print(\"Creating ChatML format dataset for Axolotl...\")\n",
    "chatml_dataset = create_chatml_dataset(df)\n",
    "\n",
    "print(f\"Created {len(chatml_dataset)} ChatML training examples\")\n",
    "\n",
    "# Save to JSONL file for Axolotl\n",
    "chatml_output_file = \"chatml_training_data.jsonl\"\n",
    "with open(chatml_output_file, 'w') as f:\n",
    "    for entry in chatml_dataset:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Saved ChatML training data to {chatml_output_file}\")\n",
    "\n",
    "# Display a sample ChatML entry\n",
    "print(\"\\nSample ChatML training entry:\")\n",
    "print(json.dumps(chatml_dataset[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile axolotl.yaml\n",
    "# axolotl_qwen3_0.6b.yaml\n",
    "# Full fine-tune configuration for Qwen3-0.6B on SQL generation dataset\n",
    "# Adapted from https://github.com/axolotl-ai-cloud/axolotl/blob/main/examples/qwen3/32b-qlora.yaml\n",
    "\n",
    "base_model: Qwen/Qwen3-0.6B\n",
    "# Automatically upload checkpoint and final model to HF\n",
    "# hub_model_id: username/custom_model_name\n",
    "\n",
    "plugins:\n",
    "  - axolotl.integrations.cut_cross_entropy.CutCrossEntropyPlugin\n",
    "strict: false\n",
    "\n",
    "chat_template: qwen3\n",
    "datasets:\n",
    "  - path: chatml_training_data.jsonl\n",
    "    type: chat_template\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: role\n",
    "      content: content\n",
    "val_set_size: 0.2\n",
    "output_dir: ./outputs/out\n",
    "dataset_prepared_path: last_run_prepared\n",
    "\n",
    "sequence_len: 2048\n",
    "sample_packing: true\n",
    "eval_sample_packing: true\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "# Since we're training a small model, we will just load full precision and not use LoRA.\n",
    "# load_in_4bit: true\n",
    "# adapter: qlora\n",
    "# lora_r: 16\n",
    "# lora_alpha: 32\n",
    "# lora_target_modules:\n",
    "#   - q_proj\n",
    "#   - k_proj\n",
    "#   - v_proj\n",
    "#   - o_proj\n",
    "#   - down_proj\n",
    "#   - up_proj\n",
    "# lora_mlp_kernel: true\n",
    "# lora_qkv_kernel: true\n",
    "# lora_o_kernel: true\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 2\n",
    "micro_batch_size: 4\n",
    "num_epochs: 4\n",
    "optimizer: adamw_torch\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "bf16: auto\n",
    "tf32: true\n",
    "\n",
    "gradient_checkpointing: offload\n",
    "gradient_checkpointing_kwargs:\n",
    "  use_reentrant: false\n",
    "resume_from_checkpoint:\n",
    "logging_steps: 1\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 4\n",
    "saves_per_epoch: 1\n",
    "weight_decay: 0.0\n",
    "special_tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
